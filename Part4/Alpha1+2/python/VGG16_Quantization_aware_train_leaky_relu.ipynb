{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "radical-fifty",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Building model...\n",
      "VGG_quant_leaky(\n",
      "  (features): Sequential(\n",
      "    (0): QuantConv2d(\n",
      "      3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "      (weight_quant): weight_quantize_fn()\n",
      "    )\n",
      "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): LeakyReLU(negative_slope=0.015625, inplace=True)\n",
      "    (3): QuantConv2d(\n",
      "      64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "      (weight_quant): weight_quantize_fn()\n",
      "    )\n",
      "    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (5): LeakyReLU(negative_slope=0.015625, inplace=True)\n",
      "    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (7): QuantConv2d(\n",
      "      64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "      (weight_quant): weight_quantize_fn()\n",
      "    )\n",
      "    (8): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (9): LeakyReLU(negative_slope=0.015625, inplace=True)\n",
      "    (10): QuantConv2d(\n",
      "      128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "      (weight_quant): weight_quantize_fn()\n",
      "    )\n",
      "    (11): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (12): LeakyReLU(negative_slope=0.015625, inplace=True)\n",
      "    (13): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (14): QuantConv2d(\n",
      "      128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "      (weight_quant): weight_quantize_fn()\n",
      "    )\n",
      "    (15): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (16): LeakyReLU(negative_slope=0.015625, inplace=True)\n",
      "    (17): QuantConv2d(\n",
      "      256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "      (weight_quant): weight_quantize_fn()\n",
      "    )\n",
      "    (18): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (19): LeakyReLU(negative_slope=0.015625, inplace=True)\n",
      "    (20): QuantConv2d(\n",
      "      256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "      (weight_quant): weight_quantize_fn()\n",
      "    )\n",
      "    (21): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (22): LeakyReLU(negative_slope=0.015625, inplace=True)\n",
      "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (24): QuantConv2d(\n",
      "      256, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "      (weight_quant): weight_quantize_fn()\n",
      "    )\n",
      "    (25): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (26): LeakyReLU(negative_slope=0.015625, inplace=True)\n",
      "    (27): QuantConv2d(\n",
      "      8, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "      (weight_quant): weight_quantize_fn()\n",
      "    )\n",
      "    (28): LeakyReLU(negative_slope=0.015625, inplace=True)\n",
      "    (29): QuantConv2d(\n",
      "      8, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "      (weight_quant): weight_quantize_fn()\n",
      "    )\n",
      "    (30): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (31): LeakyReLU(negative_slope=0.015625, inplace=True)\n",
      "    (32): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (33): QuantConv2d(\n",
      "      512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "      (weight_quant): weight_quantize_fn()\n",
      "    )\n",
      "    (34): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (35): LeakyReLU(negative_slope=0.015625, inplace=True)\n",
      "    (36): QuantConv2d(\n",
      "      512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "      (weight_quant): weight_quantize_fn()\n",
      "    )\n",
      "    (37): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (38): LeakyReLU(negative_slope=0.015625, inplace=True)\n",
      "    (39): QuantConv2d(\n",
      "      512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "      (weight_quant): weight_quantize_fn()\n",
      "    )\n",
      "    (40): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (41): LeakyReLU(negative_slope=0.015625, inplace=True)\n",
      "    (42): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (43): AvgPool2d(kernel_size=1, stride=1, padding=0)\n",
      "  )\n",
      "  (classifier): Linear(in_features=512, out_features=10, bias=True)\n",
      ")\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "import os\n",
    "import time\n",
    "import shutil\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torch.backends.cudnn as cudnn\n",
    "     \n",
    "\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import importlib\n",
    "from models import *\n",
    "# importlib.reload(vgg_quant)\n",
    "\n",
    "global best_prec\n",
    "use_gpu = torch.cuda.is_available()\n",
    "print('=> Building model...')\n",
    "    \n",
    "    \n",
    "    \n",
    "batch_size = 128\n",
    "model_name = \"VGG16_quantLeaky\"\n",
    "model = VGG16_quant_leaky()\n",
    "\n",
    "\n",
    "print(model)\n",
    "\n",
    "normalize = transforms.Normalize(mean=[0.491, 0.482, 0.447], std=[0.247, 0.243, 0.262])\n",
    "\n",
    "\n",
    "train_dataset = torchvision.datasets.CIFAR10(\n",
    "    root='./data',\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=transforms.Compose([\n",
    "        transforms.RandomCrop(32, padding=4),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        normalize,\n",
    "    ]))\n",
    "trainloader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=2)\n",
    "\n",
    "\n",
    "test_dataset = torchvision.datasets.CIFAR10(\n",
    "    root='./data',\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        normalize,\n",
    "    ]))\n",
    "\n",
    "testloader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=2)\n",
    "\n",
    "\n",
    "print_freq = 100 # every 100 batches, accuracy printed. Here, each batch includes \"batch_size\" data points\n",
    "# CIFAR10 has 50,000 training data, and 10,000 validation data.\n",
    "\n",
    "def train(trainloader, model, criterion, optimizer, epoch):\n",
    "    batch_time = AverageMeter()\n",
    "    data_time = AverageMeter()\n",
    "    losses = AverageMeter()\n",
    "    top1 = AverageMeter()\n",
    "\n",
    "    model.train()\n",
    "\n",
    "    end = time.time()\n",
    "    for i, (input, target) in enumerate(trainloader):\n",
    "        # measure data loading time\n",
    "        data_time.update(time.time() - end)\n",
    "\n",
    "        input, target = input.cuda(), target.cuda()\n",
    "\n",
    "        # compute output\n",
    "        output = model(input)\n",
    "        loss = criterion(output, target)\n",
    "\n",
    "        # measure accuracy and record loss\n",
    "        prec = accuracy(output, target)[0]\n",
    "        losses.update(loss.item(), input.size(0))\n",
    "        top1.update(prec.item(), input.size(0))\n",
    "\n",
    "        # compute gradient and do SGD step\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # measure elapsed time\n",
    "        batch_time.update(time.time() - end)\n",
    "        end = time.time()\n",
    "\n",
    "\n",
    "        if i % print_freq == 0:\n",
    "            print('Epoch: [{0}][{1}/{2}]\\t'\n",
    "                  'Time {batch_time.val:.3f} ({batch_time.avg:.3f})\\t'\n",
    "                  'Data {data_time.val:.3f} ({data_time.avg:.3f})\\t'\n",
    "                  'Loss {loss.val:.4f} ({loss.avg:.4f})\\t'\n",
    "                  'Prec {top1.val:.3f}% ({top1.avg:.3f}%)'.format(\n",
    "                   epoch, i, len(trainloader), batch_time=batch_time,\n",
    "                   data_time=data_time, loss=losses, top1=top1))\n",
    "\n",
    "            \n",
    "\n",
    "def validate(val_loader, model, criterion ):\n",
    "    batch_time = AverageMeter()\n",
    "    losses = AverageMeter()\n",
    "    top1 = AverageMeter()\n",
    "\n",
    "    # switch to evaluate mode\n",
    "    model.eval()\n",
    "\n",
    "    end = time.time()\n",
    "    with torch.no_grad():\n",
    "        for i, (input, target) in enumerate(val_loader):\n",
    "         \n",
    "            input, target = input.cuda(), target.cuda()\n",
    "\n",
    "            # compute output\n",
    "            output = model(input)\n",
    "            loss = criterion(output, target)\n",
    "\n",
    "            # measure accuracy and record loss\n",
    "            prec = accuracy(output, target)[0]\n",
    "            losses.update(loss.item(), input.size(0))\n",
    "            top1.update(prec.item(), input.size(0))\n",
    "\n",
    "            # measure elapsed time\n",
    "            batch_time.update(time.time() - end)\n",
    "            end = time.time()\n",
    "\n",
    "            if i % print_freq == 0:  # This line shows how frequently print out the status. e.g., i%5 => every 5 batch, prints out\n",
    "                print('Test: [{0}/{1}]\\t'\n",
    "                  'Time {batch_time.val:.3f} ({batch_time.avg:.3f})\\t'\n",
    "                  'Loss {loss.val:.4f} ({loss.avg:.4f})\\t'\n",
    "                  'Prec {top1.val:.3f}% ({top1.avg:.3f}%)'.format(\n",
    "                   i, len(val_loader), batch_time=batch_time, loss=losses,\n",
    "                   top1=top1))\n",
    "\n",
    "    print(' * Prec {top1.avg:.3f}% '.format(top1=top1))\n",
    "    return top1.avg\n",
    "\n",
    "\n",
    "def accuracy(output, target, topk=(1,)):\n",
    "    \"\"\"Computes the precision@k for the specified values of k\"\"\"\n",
    "    maxk = max(topk)\n",
    "    batch_size = target.size(0)\n",
    "\n",
    "    _, pred = output.topk(maxk, 1, True, True)\n",
    "    pred = pred.t()\n",
    "    correct = pred.eq(target.view(1, -1).expand_as(pred))\n",
    "\n",
    "    res = []\n",
    "    for k in topk:\n",
    "        correct_k = correct[:k].view(-1).float().sum(0)\n",
    "        res.append(correct_k.mul_(100.0 / batch_size))\n",
    "    return res\n",
    "\n",
    "\n",
    "class AverageMeter(object):\n",
    "    \"\"\"Computes and stores the average and current value\"\"\"\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count\n",
    "\n",
    "        \n",
    "def save_checkpoint(state, is_best, fdir):\n",
    "    filepath = os.path.join(fdir, 'checkpoint.pth')\n",
    "    torch.save(state, filepath)\n",
    "    if is_best:\n",
    "        shutil.copyfile(filepath, os.path.join(fdir, 'model_best.pth.tar'))\n",
    "\n",
    "\n",
    "def adjust_learning_rate(optimizer, epoch):\n",
    "    \"\"\"For resnet, the lr starts from 0.1, and is divided by 10 at 80 and 120 epochs\"\"\"\n",
    "    adjust_list = [25, 45, 65]\n",
    "    if epoch in adjust_list:\n",
    "        for param_group in optimizer.param_groups:\n",
    "            param_group['lr'] = param_group['lr'] * 0.1        \n",
    "\n",
    "#model = nn.DataParallel(model).cuda()\n",
    "#all_params = checkpoint['state_dict']\n",
    "#model.load_state_dict(all_params, strict=False)\n",
    "#criterion = nn.CrossEntropyLoss().cuda()\n",
    "#validate(testloader, model, criterion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "junior-reminder",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [0][0/391]\tTime 0.175 (0.175)\tData 0.155 (0.155)\tLoss 0.3001 (0.3001)\tPrec 91.406% (91.406%)\n",
      "Epoch: [0][100/391]\tTime 0.023 (0.025)\tData 0.001 (0.003)\tLoss 0.7054 (0.7871)\tPrec 75.781% (73.646%)\n",
      "Epoch: [0][200/391]\tTime 0.023 (0.024)\tData 0.001 (0.002)\tLoss 0.6547 (0.7907)\tPrec 78.906% (73.640%)\n",
      "Epoch: [0][300/391]\tTime 0.021 (0.023)\tData 0.001 (0.002)\tLoss 0.6937 (0.7799)\tPrec 74.219% (73.920%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.123 (0.123)\tLoss 0.8958 (0.8958)\tPrec 73.438% (73.438%)\n",
      " * Prec 72.980% \n",
      "best acc: 72.980000\n",
      "Epoch: [1][0/391]\tTime 0.162 (0.162)\tData 0.140 (0.140)\tLoss 0.6035 (0.6035)\tPrec 79.688% (79.688%)\n",
      "Epoch: [1][100/391]\tTime 0.021 (0.022)\tData 0.001 (0.003)\tLoss 0.5901 (0.7046)\tPrec 81.250% (76.617%)\n",
      "Epoch: [1][200/391]\tTime 0.020 (0.021)\tData 0.001 (0.002)\tLoss 0.8760 (0.7004)\tPrec 71.094% (76.625%)\n",
      "Epoch: [1][300/391]\tTime 0.020 (0.021)\tData 0.001 (0.002)\tLoss 0.5835 (0.6994)\tPrec 82.812% (76.646%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.115 (0.115)\tLoss 1.0082 (1.0082)\tPrec 73.438% (73.438%)\n",
      " * Prec 68.250% \n",
      "best acc: 72.980000\n",
      "Epoch: [2][0/391]\tTime 0.198 (0.198)\tData 0.179 (0.179)\tLoss 0.7180 (0.7180)\tPrec 76.562% (76.562%)\n",
      "Epoch: [2][100/391]\tTime 0.020 (0.023)\tData 0.001 (0.003)\tLoss 0.8006 (0.6319)\tPrec 75.781% (79.100%)\n",
      "Epoch: [2][200/391]\tTime 0.020 (0.022)\tData 0.001 (0.002)\tLoss 0.6098 (0.6460)\tPrec 78.906% (78.626%)\n",
      "Epoch: [2][300/391]\tTime 0.020 (0.021)\tData 0.001 (0.002)\tLoss 0.7023 (0.6469)\tPrec 75.781% (78.571%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.163 (0.163)\tLoss 0.7925 (0.7925)\tPrec 72.656% (72.656%)\n",
      " * Prec 75.970% \n",
      "best acc: 75.970000\n",
      "Epoch: [3][0/391]\tTime 0.182 (0.182)\tData 0.162 (0.162)\tLoss 0.6688 (0.6688)\tPrec 76.562% (76.562%)\n",
      "Epoch: [3][100/391]\tTime 0.023 (0.024)\tData 0.001 (0.003)\tLoss 0.5399 (0.6246)\tPrec 81.250% (79.231%)\n",
      "Epoch: [3][200/391]\tTime 0.023 (0.023)\tData 0.001 (0.002)\tLoss 0.9211 (0.6268)\tPrec 69.531% (79.244%)\n",
      "Epoch: [3][300/391]\tTime 0.023 (0.023)\tData 0.001 (0.002)\tLoss 0.7085 (0.6235)\tPrec 77.344% (79.360%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.109 (0.109)\tLoss 0.6722 (0.6722)\tPrec 75.781% (75.781%)\n",
      " * Prec 77.990% \n",
      "best acc: 77.990000\n",
      "Epoch: [4][0/391]\tTime 0.138 (0.138)\tData 0.118 (0.118)\tLoss 0.6535 (0.6535)\tPrec 75.000% (75.000%)\n",
      "Epoch: [4][100/391]\tTime 0.020 (0.021)\tData 0.001 (0.002)\tLoss 0.6752 (0.6075)\tPrec 80.469% (80.291%)\n",
      "Epoch: [4][200/391]\tTime 0.023 (0.021)\tData 0.001 (0.002)\tLoss 0.6659 (0.6109)\tPrec 79.688% (79.921%)\n",
      "Epoch: [4][300/391]\tTime 0.020 (0.021)\tData 0.001 (0.002)\tLoss 0.5514 (0.5978)\tPrec 85.156% (80.308%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.091 (0.091)\tLoss 0.7553 (0.7553)\tPrec 74.219% (74.219%)\n",
      " * Prec 76.200% \n",
      "best acc: 77.990000\n",
      "Epoch: [5][0/391]\tTime 0.121 (0.121)\tData 0.103 (0.103)\tLoss 0.5199 (0.5199)\tPrec 82.812% (82.812%)\n",
      "Epoch: [5][100/391]\tTime 0.023 (0.024)\tData 0.001 (0.002)\tLoss 0.5920 (0.5745)\tPrec 83.594% (81.026%)\n",
      "Epoch: [5][200/391]\tTime 0.023 (0.023)\tData 0.001 (0.002)\tLoss 0.5013 (0.5762)\tPrec 83.594% (81.025%)\n",
      "Epoch: [5][300/391]\tTime 0.023 (0.023)\tData 0.001 (0.002)\tLoss 0.5996 (0.5739)\tPrec 79.688% (81.081%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.179 (0.179)\tLoss 0.7602 (0.7602)\tPrec 72.656% (72.656%)\n",
      " * Prec 74.720% \n",
      "best acc: 77.990000\n",
      "Epoch: [6][0/391]\tTime 0.200 (0.200)\tData 0.176 (0.176)\tLoss 0.5487 (0.5487)\tPrec 83.594% (83.594%)\n",
      "Epoch: [6][100/391]\tTime 0.021 (0.025)\tData 0.001 (0.003)\tLoss 0.5043 (0.5840)\tPrec 82.031% (80.507%)\n",
      "Epoch: [6][200/391]\tTime 0.020 (0.023)\tData 0.001 (0.002)\tLoss 0.6223 (0.5740)\tPrec 78.906% (80.889%)\n",
      "Epoch: [6][300/391]\tTime 0.020 (0.022)\tData 0.001 (0.002)\tLoss 0.5607 (0.5740)\tPrec 81.250% (80.967%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.090 (0.090)\tLoss 0.8817 (0.8817)\tPrec 74.219% (74.219%)\n",
      " * Prec 74.010% \n",
      "best acc: 77.990000\n",
      "Epoch: [7][0/391]\tTime 0.129 (0.129)\tData 0.110 (0.110)\tLoss 0.6843 (0.6843)\tPrec 78.906% (78.906%)\n",
      "Epoch: [7][100/391]\tTime 0.019 (0.022)\tData 0.001 (0.002)\tLoss 0.7216 (0.5892)\tPrec 75.000% (80.577%)\n",
      "Epoch: [7][200/391]\tTime 0.023 (0.021)\tData 0.001 (0.002)\tLoss 0.6439 (0.5727)\tPrec 82.031% (81.044%)\n",
      "Epoch: [7][300/391]\tTime 0.023 (0.021)\tData 0.001 (0.002)\tLoss 0.5349 (0.5778)\tPrec 86.719% (80.801%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.172 (0.172)\tLoss 0.6823 (0.6823)\tPrec 78.125% (78.125%)\n",
      " * Prec 77.680% \n",
      "best acc: 77.990000\n",
      "Epoch: [8][0/391]\tTime 0.207 (0.207)\tData 0.183 (0.183)\tLoss 0.4788 (0.4788)\tPrec 84.375% (84.375%)\n",
      "Epoch: [8][100/391]\tTime 0.021 (0.025)\tData 0.001 (0.003)\tLoss 0.4754 (0.5784)\tPrec 84.375% (80.917%)\n",
      "Epoch: [8][200/391]\tTime 0.022 (0.023)\tData 0.001 (0.002)\tLoss 0.4865 (0.5714)\tPrec 87.500% (81.168%)\n",
      "Epoch: [8][300/391]\tTime 0.022 (0.022)\tData 0.001 (0.002)\tLoss 0.5023 (0.5669)\tPrec 80.469% (81.268%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.133 (0.133)\tLoss 0.6647 (0.6647)\tPrec 76.562% (76.562%)\n",
      " * Prec 74.520% \n",
      "best acc: 77.990000\n",
      "Epoch: [9][0/391]\tTime 0.246 (0.246)\tData 0.189 (0.189)\tLoss 0.4459 (0.4459)\tPrec 85.938% (85.938%)\n",
      "Epoch: [9][100/391]\tTime 0.022 (0.024)\tData 0.001 (0.003)\tLoss 0.5634 (0.5454)\tPrec 81.250% (81.675%)\n",
      "Epoch: [9][200/391]\tTime 0.021 (0.023)\tData 0.001 (0.002)\tLoss 0.6410 (0.5382)\tPrec 79.688% (81.946%)\n",
      "Epoch: [9][300/391]\tTime 0.022 (0.022)\tData 0.001 (0.002)\tLoss 0.5095 (0.5398)\tPrec 82.031% (81.930%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.100 (0.100)\tLoss 0.7162 (0.7162)\tPrec 78.125% (78.125%)\n",
      " * Prec 76.410% \n",
      "best acc: 77.990000\n",
      "Epoch: [10][0/391]\tTime 0.202 (0.202)\tData 0.182 (0.182)\tLoss 0.6692 (0.6692)\tPrec 80.469% (80.469%)\n",
      "Epoch: [10][100/391]\tTime 0.023 (0.023)\tData 0.001 (0.003)\tLoss 0.5034 (0.5518)\tPrec 82.031% (81.250%)\n",
      "Epoch: [10][200/391]\tTime 0.022 (0.022)\tData 0.001 (0.002)\tLoss 0.4947 (0.5424)\tPrec 82.031% (81.786%)\n",
      "Epoch: [10][300/391]\tTime 0.023 (0.022)\tData 0.001 (0.002)\tLoss 0.6451 (0.5361)\tPrec 78.906% (82.055%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.091 (0.091)\tLoss 0.5198 (0.5198)\tPrec 83.594% (83.594%)\n",
      " * Prec 80.120% \n",
      "best acc: 80.120000\n",
      "Epoch: [11][0/391]\tTime 0.155 (0.155)\tData 0.136 (0.136)\tLoss 0.6022 (0.6022)\tPrec 79.688% (79.688%)\n",
      "Epoch: [11][100/391]\tTime 0.021 (0.023)\tData 0.001 (0.003)\tLoss 0.5196 (0.4963)\tPrec 81.250% (83.609%)\n",
      "Epoch: [11][200/391]\tTime 0.022 (0.022)\tData 0.001 (0.002)\tLoss 0.5805 (0.5023)\tPrec 82.031% (83.419%)\n",
      "Epoch: [11][300/391]\tTime 0.022 (0.022)\tData 0.001 (0.002)\tLoss 0.6368 (0.5051)\tPrec 78.125% (83.287%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.125 (0.125)\tLoss 0.5987 (0.5987)\tPrec 78.125% (78.125%)\n",
      " * Prec 78.580% \n",
      "best acc: 80.120000\n",
      "Epoch: [12][0/391]\tTime 0.202 (0.202)\tData 0.182 (0.182)\tLoss 0.4499 (0.4499)\tPrec 85.938% (85.938%)\n",
      "Epoch: [12][100/391]\tTime 0.021 (0.022)\tData 0.001 (0.003)\tLoss 0.4070 (0.4603)\tPrec 86.719% (84.808%)\n",
      "Epoch: [12][200/391]\tTime 0.020 (0.021)\tData 0.001 (0.002)\tLoss 0.3227 (0.4505)\tPrec 90.625% (85.071%)\n",
      "Epoch: [12][300/391]\tTime 0.021 (0.021)\tData 0.001 (0.002)\tLoss 0.4007 (0.4537)\tPrec 85.156% (84.897%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.174 (0.174)\tLoss 0.5531 (0.5531)\tPrec 83.594% (83.594%)\n",
      " * Prec 79.990% \n",
      "best acc: 80.120000\n",
      "Epoch: [13][0/391]\tTime 0.196 (0.196)\tData 0.177 (0.177)\tLoss 0.4605 (0.4605)\tPrec 84.375% (84.375%)\n",
      "Epoch: [13][100/391]\tTime 0.017 (0.024)\tData 0.001 (0.003)\tLoss 0.4548 (0.4164)\tPrec 82.031% (85.821%)\n",
      "Epoch: [13][200/391]\tTime 0.021 (0.023)\tData 0.001 (0.002)\tLoss 0.4767 (0.4344)\tPrec 82.812% (85.335%)\n",
      "Epoch: [13][300/391]\tTime 0.023 (0.022)\tData 0.001 (0.002)\tLoss 0.5211 (0.4317)\tPrec 82.031% (85.372%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.154 (0.154)\tLoss 0.6516 (0.6516)\tPrec 75.781% (75.781%)\n",
      " * Prec 75.250% \n",
      "best acc: 80.120000\n",
      "Epoch: [14][0/391]\tTime 0.127 (0.127)\tData 0.108 (0.108)\tLoss 0.5323 (0.5323)\tPrec 82.031% (82.031%)\n",
      "Epoch: [14][100/391]\tTime 0.021 (0.023)\tData 0.001 (0.002)\tLoss 0.4707 (0.4490)\tPrec 84.375% (84.971%)\n",
      "Epoch: [14][200/391]\tTime 0.023 (0.022)\tData 0.001 (0.002)\tLoss 0.4302 (0.4407)\tPrec 83.594% (85.378%)\n",
      "Epoch: [14][300/391]\tTime 0.021 (0.022)\tData 0.001 (0.002)\tLoss 0.3778 (0.4396)\tPrec 86.719% (85.426%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.159 (0.159)\tLoss 0.4816 (0.4816)\tPrec 86.719% (86.719%)\n",
      " * Prec 83.430% \n",
      "best acc: 83.430000\n",
      "Epoch: [15][0/391]\tTime 0.151 (0.151)\tData 0.131 (0.131)\tLoss 0.3796 (0.3796)\tPrec 90.625% (90.625%)\n",
      "Epoch: [15][100/391]\tTime 0.022 (0.023)\tData 0.001 (0.003)\tLoss 0.4312 (0.4260)\tPrec 85.938% (85.744%)\n",
      "Epoch: [15][200/391]\tTime 0.022 (0.022)\tData 0.001 (0.002)\tLoss 0.3760 (0.4151)\tPrec 87.500% (86.140%)\n",
      "Epoch: [15][300/391]\tTime 0.022 (0.022)\tData 0.001 (0.002)\tLoss 0.4452 (0.4229)\tPrec 81.250% (85.808%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.133 (0.133)\tLoss 0.5594 (0.5594)\tPrec 82.031% (82.031%)\n",
      " * Prec 80.750% \n",
      "best acc: 83.430000\n",
      "Epoch: [16][0/391]\tTime 0.198 (0.198)\tData 0.178 (0.178)\tLoss 0.4179 (0.4179)\tPrec 85.156% (85.156%)\n",
      "Epoch: [16][100/391]\tTime 0.021 (0.024)\tData 0.001 (0.003)\tLoss 0.4480 (0.3985)\tPrec 82.031% (86.858%)\n",
      "Epoch: [16][200/391]\tTime 0.023 (0.023)\tData 0.001 (0.002)\tLoss 0.4454 (0.4188)\tPrec 88.281% (86.136%)\n",
      "Epoch: [16][300/391]\tTime 0.021 (0.023)\tData 0.001 (0.002)\tLoss 0.4749 (0.4197)\tPrec 83.594% (86.135%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.082 (0.082)\tLoss 0.8075 (0.8075)\tPrec 74.219% (74.219%)\n",
      " * Prec 77.710% \n",
      "best acc: 83.430000\n",
      "Epoch: [17][0/391]\tTime 0.211 (0.211)\tData 0.185 (0.185)\tLoss 0.3463 (0.3463)\tPrec 84.375% (84.375%)\n",
      "Epoch: [17][100/391]\tTime 0.023 (0.025)\tData 0.001 (0.003)\tLoss 0.4325 (0.4119)\tPrec 86.719% (86.077%)\n",
      "Epoch: [17][200/391]\tTime 0.023 (0.024)\tData 0.001 (0.002)\tLoss 0.5149 (0.4085)\tPrec 82.812% (86.400%)\n",
      "Epoch: [17][300/391]\tTime 0.026 (0.024)\tData 0.002 (0.002)\tLoss 0.4930 (0.4109)\tPrec 83.594% (86.285%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.075 (0.075)\tLoss 0.6380 (0.6380)\tPrec 81.250% (81.250%)\n",
      " * Prec 80.390% \n",
      "best acc: 83.430000\n",
      "Epoch: [18][0/391]\tTime 0.202 (0.202)\tData 0.181 (0.181)\tLoss 0.3597 (0.3597)\tPrec 87.500% (87.500%)\n",
      "Epoch: [18][100/391]\tTime 0.021 (0.022)\tData 0.001 (0.003)\tLoss 0.3985 (0.4000)\tPrec 85.156% (86.804%)\n",
      "Epoch: [18][200/391]\tTime 0.021 (0.021)\tData 0.001 (0.002)\tLoss 0.4296 (0.4101)\tPrec 85.156% (86.388%)\n",
      "Epoch: [18][300/391]\tTime 0.020 (0.021)\tData 0.001 (0.002)\tLoss 0.3021 (0.4087)\tPrec 91.406% (86.553%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.173 (0.173)\tLoss 0.7598 (0.7598)\tPrec 76.562% (76.562%)\n",
      " * Prec 79.120% \n",
      "best acc: 83.430000\n",
      "Epoch: [19][0/391]\tTime 0.198 (0.198)\tData 0.179 (0.179)\tLoss 0.4949 (0.4949)\tPrec 85.938% (85.938%)\n",
      "Epoch: [19][100/391]\tTime 0.019 (0.023)\tData 0.001 (0.003)\tLoss 0.5344 (0.3788)\tPrec 84.375% (87.283%)\n",
      "Epoch: [19][200/391]\tTime 0.019 (0.022)\tData 0.001 (0.002)\tLoss 0.3296 (0.3962)\tPrec 88.281% (86.800%)\n",
      "Epoch: [19][300/391]\tTime 0.019 (0.022)\tData 0.001 (0.002)\tLoss 0.4509 (0.3990)\tPrec 85.156% (86.721%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.171 (0.171)\tLoss 0.5222 (0.5222)\tPrec 86.719% (86.719%)\n",
      " * Prec 79.760% \n",
      "best acc: 83.430000\n",
      "Epoch: [20][0/391]\tTime 0.125 (0.125)\tData 0.106 (0.106)\tLoss 0.3402 (0.3402)\tPrec 89.062% (89.062%)\n",
      "Epoch: [20][100/391]\tTime 0.020 (0.023)\tData 0.001 (0.002)\tLoss 0.3436 (0.3941)\tPrec 85.938% (86.827%)\n",
      "Epoch: [20][200/391]\tTime 0.020 (0.021)\tData 0.001 (0.002)\tLoss 0.3672 (0.3954)\tPrec 87.500% (86.882%)\n",
      "Epoch: [20][300/391]\tTime 0.020 (0.021)\tData 0.001 (0.001)\tLoss 0.2724 (0.3961)\tPrec 89.062% (86.794%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.145 (0.145)\tLoss 0.5319 (0.5319)\tPrec 85.938% (85.938%)\n",
      " * Prec 81.080% \n",
      "best acc: 83.430000\n",
      "Epoch: [21][0/391]\tTime 0.123 (0.123)\tData 0.104 (0.104)\tLoss 0.5496 (0.5496)\tPrec 84.375% (84.375%)\n",
      "Epoch: [21][100/391]\tTime 0.023 (0.024)\tData 0.001 (0.002)\tLoss 0.3065 (0.3979)\tPrec 90.625% (86.680%)\n",
      "Epoch: [21][200/391]\tTime 0.023 (0.023)\tData 0.001 (0.002)\tLoss 0.3779 (0.3912)\tPrec 87.500% (86.874%)\n",
      "Epoch: [21][300/391]\tTime 0.023 (0.023)\tData 0.001 (0.002)\tLoss 0.3893 (0.3921)\tPrec 88.281% (86.862%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.138 (0.138)\tLoss 0.4157 (0.4157)\tPrec 86.719% (86.719%)\n",
      " * Prec 84.000% \n",
      "best acc: 84.000000\n",
      "Epoch: [22][0/391]\tTime 0.193 (0.193)\tData 0.170 (0.170)\tLoss 0.3332 (0.3332)\tPrec 86.719% (86.719%)\n",
      "Epoch: [22][100/391]\tTime 0.023 (0.024)\tData 0.001 (0.003)\tLoss 0.3542 (0.3882)\tPrec 89.844% (87.276%)\n",
      "Epoch: [22][200/391]\tTime 0.023 (0.024)\tData 0.001 (0.002)\tLoss 0.2396 (0.3874)\tPrec 92.969% (87.321%)\n",
      "Epoch: [22][300/391]\tTime 0.025 (0.024)\tData 0.002 (0.002)\tLoss 0.4308 (0.3951)\tPrec 88.281% (86.955%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.165 (0.165)\tLoss 0.5796 (0.5796)\tPrec 82.031% (82.031%)\n",
      " * Prec 79.650% \n",
      "best acc: 84.000000\n",
      "Epoch: [23][0/391]\tTime 0.141 (0.141)\tData 0.122 (0.122)\tLoss 0.3624 (0.3624)\tPrec 88.281% (88.281%)\n",
      "Epoch: [23][100/391]\tTime 0.022 (0.023)\tData 0.001 (0.002)\tLoss 0.3525 (0.3592)\tPrec 86.719% (87.794%)\n",
      "Epoch: [23][200/391]\tTime 0.022 (0.022)\tData 0.001 (0.002)\tLoss 0.4377 (0.3761)\tPrec 89.844% (87.430%)\n",
      "Epoch: [23][300/391]\tTime 0.021 (0.022)\tData 0.001 (0.002)\tLoss 0.3967 (0.3752)\tPrec 85.938% (87.495%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.170 (0.170)\tLoss 0.4497 (0.4497)\tPrec 84.375% (84.375%)\n",
      " * Prec 83.760% \n",
      "best acc: 84.000000\n",
      "Epoch: [24][0/391]\tTime 0.202 (0.202)\tData 0.182 (0.182)\tLoss 0.3314 (0.3314)\tPrec 86.719% (86.719%)\n",
      "Epoch: [24][100/391]\tTime 0.022 (0.024)\tData 0.001 (0.003)\tLoss 0.3102 (0.3569)\tPrec 89.844% (88.150%)\n",
      "Epoch: [24][200/391]\tTime 0.025 (0.023)\tData 0.001 (0.002)\tLoss 0.4092 (0.3701)\tPrec 85.938% (87.757%)\n",
      "Epoch: [24][300/391]\tTime 0.023 (0.023)\tData 0.001 (0.002)\tLoss 0.3586 (0.3723)\tPrec 87.500% (87.718%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.142 (0.142)\tLoss 0.4260 (0.4260)\tPrec 84.375% (84.375%)\n",
      " * Prec 81.820% \n",
      "best acc: 84.000000\n",
      "Epoch: [25][0/391]\tTime 0.149 (0.149)\tData 0.131 (0.131)\tLoss 0.2820 (0.2820)\tPrec 87.500% (87.500%)\n",
      "Epoch: [25][100/391]\tTime 0.021 (0.022)\tData 0.001 (0.003)\tLoss 0.1608 (0.2849)\tPrec 93.750% (90.432%)\n",
      "Epoch: [25][200/391]\tTime 0.021 (0.021)\tData 0.001 (0.002)\tLoss 0.2814 (0.2567)\tPrec 91.406% (91.406%)\n",
      "Epoch: [25][300/391]\tTime 0.021 (0.021)\tData 0.001 (0.002)\tLoss 0.2499 (0.2440)\tPrec 91.406% (91.819%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.138 (0.138)\tLoss 0.2351 (0.2351)\tPrec 93.750% (93.750%)\n",
      " * Prec 90.020% \n",
      "best acc: 90.020000\n",
      "Epoch: [26][0/391]\tTime 0.161 (0.161)\tData 0.141 (0.141)\tLoss 0.1902 (0.1902)\tPrec 93.750% (93.750%)\n",
      "Epoch: [26][100/391]\tTime 0.024 (0.022)\tData 0.001 (0.003)\tLoss 0.1714 (0.1911)\tPrec 93.750% (93.502%)\n",
      "Epoch: [26][200/391]\tTime 0.024 (0.022)\tData 0.001 (0.002)\tLoss 0.1989 (0.1910)\tPrec 93.750% (93.571%)\n",
      "Epoch: [26][300/391]\tTime 0.024 (0.022)\tData 0.001 (0.002)\tLoss 0.1295 (0.1906)\tPrec 94.531% (93.576%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.094 (0.094)\tLoss 0.2106 (0.2106)\tPrec 95.312% (95.312%)\n",
      " * Prec 90.130% \n",
      "best acc: 90.130000\n",
      "Epoch: [27][0/391]\tTime 0.150 (0.150)\tData 0.126 (0.126)\tLoss 0.1471 (0.1471)\tPrec 93.750% (93.750%)\n",
      "Epoch: [27][100/391]\tTime 0.023 (0.023)\tData 0.001 (0.003)\tLoss 0.2183 (0.1736)\tPrec 92.188% (94.083%)\n",
      "Epoch: [27][200/391]\tTime 0.023 (0.022)\tData 0.001 (0.002)\tLoss 0.1842 (0.1759)\tPrec 93.750% (93.956%)\n",
      "Epoch: [27][300/391]\tTime 0.020 (0.022)\tData 0.001 (0.002)\tLoss 0.1255 (0.1740)\tPrec 96.094% (94.033%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.094 (0.094)\tLoss 0.2313 (0.2313)\tPrec 92.969% (92.969%)\n",
      " * Prec 90.150% \n",
      "best acc: 90.150000\n",
      "Epoch: [28][0/391]\tTime 0.200 (0.200)\tData 0.180 (0.180)\tLoss 0.1546 (0.1546)\tPrec 94.531% (94.531%)\n",
      "Epoch: [28][100/391]\tTime 0.022 (0.023)\tData 0.001 (0.003)\tLoss 0.1251 (0.1631)\tPrec 95.312% (94.477%)\n",
      "Epoch: [28][200/391]\tTime 0.021 (0.022)\tData 0.001 (0.002)\tLoss 0.1186 (0.1653)\tPrec 98.438% (94.368%)\n",
      "Epoch: [28][300/391]\tTime 0.022 (0.022)\tData 0.001 (0.002)\tLoss 0.1282 (0.1678)\tPrec 95.312% (94.311%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.140 (0.140)\tLoss 0.1998 (0.1998)\tPrec 93.750% (93.750%)\n",
      " * Prec 90.740% \n",
      "best acc: 90.740000\n",
      "Epoch: [29][0/391]\tTime 0.163 (0.163)\tData 0.140 (0.140)\tLoss 0.1119 (0.1119)\tPrec 96.875% (96.875%)\n",
      "Epoch: [29][100/391]\tTime 0.021 (0.023)\tData 0.001 (0.003)\tLoss 0.1908 (0.1555)\tPrec 93.750% (94.864%)\n",
      "Epoch: [29][200/391]\tTime 0.021 (0.022)\tData 0.001 (0.002)\tLoss 0.1310 (0.1534)\tPrec 95.312% (94.776%)\n",
      "Epoch: [29][300/391]\tTime 0.022 (0.022)\tData 0.001 (0.002)\tLoss 0.1963 (0.1556)\tPrec 91.406% (94.635%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.107 (0.107)\tLoss 0.1790 (0.1790)\tPrec 95.312% (95.312%)\n",
      " * Prec 90.360% \n",
      "best acc: 90.740000\n",
      "Epoch: [30][0/391]\tTime 0.174 (0.174)\tData 0.155 (0.155)\tLoss 0.0831 (0.0831)\tPrec 96.094% (96.094%)\n",
      "Epoch: [30][100/391]\tTime 0.026 (0.025)\tData 0.002 (0.003)\tLoss 0.1575 (0.1506)\tPrec 96.094% (94.995%)\n",
      "Epoch: [30][200/391]\tTime 0.026 (0.025)\tData 0.002 (0.002)\tLoss 0.1133 (0.1486)\tPrec 96.094% (95.013%)\n",
      "Epoch: [30][300/391]\tTime 0.026 (0.026)\tData 0.002 (0.002)\tLoss 0.2067 (0.1506)\tPrec 92.188% (94.853%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.108 (0.108)\tLoss 0.1697 (0.1697)\tPrec 93.750% (93.750%)\n",
      " * Prec 90.190% \n",
      "best acc: 90.740000\n",
      "Epoch: [31][0/391]\tTime 0.179 (0.179)\tData 0.154 (0.154)\tLoss 0.1094 (0.1094)\tPrec 96.875% (96.875%)\n",
      "Epoch: [31][100/391]\tTime 0.023 (0.025)\tData 0.001 (0.003)\tLoss 0.1151 (0.1484)\tPrec 96.094% (94.879%)\n",
      "Epoch: [31][200/391]\tTime 0.023 (0.024)\tData 0.001 (0.002)\tLoss 0.2058 (0.1438)\tPrec 95.312% (95.192%)\n",
      "Epoch: [31][300/391]\tTime 0.022 (0.023)\tData 0.001 (0.002)\tLoss 0.1042 (0.1437)\tPrec 96.094% (95.139%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.095 (0.095)\tLoss 0.1881 (0.1881)\tPrec 94.531% (94.531%)\n",
      " * Prec 90.130% \n",
      "best acc: 90.740000\n",
      "Epoch: [32][0/391]\tTime 0.196 (0.196)\tData 0.178 (0.178)\tLoss 0.0967 (0.0967)\tPrec 96.875% (96.875%)\n",
      "Epoch: [32][100/391]\tTime 0.021 (0.022)\tData 0.001 (0.003)\tLoss 0.0942 (0.1288)\tPrec 96.875% (95.622%)\n",
      "Epoch: [32][200/391]\tTime 0.020 (0.021)\tData 0.001 (0.002)\tLoss 0.1545 (0.1317)\tPrec 93.750% (95.499%)\n",
      "Epoch: [32][300/391]\tTime 0.021 (0.021)\tData 0.001 (0.002)\tLoss 0.1404 (0.1346)\tPrec 92.188% (95.411%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.094 (0.094)\tLoss 0.2193 (0.2193)\tPrec 91.406% (91.406%)\n",
      " * Prec 90.450% \n",
      "best acc: 90.740000\n",
      "Epoch: [33][0/391]\tTime 0.208 (0.208)\tData 0.184 (0.184)\tLoss 0.1533 (0.1533)\tPrec 92.969% (92.969%)\n",
      "Epoch: [33][100/391]\tTime 0.023 (0.025)\tData 0.001 (0.003)\tLoss 0.1346 (0.1256)\tPrec 95.312% (95.916%)\n",
      "Epoch: [33][200/391]\tTime 0.021 (0.024)\tData 0.001 (0.002)\tLoss 0.1272 (0.1278)\tPrec 95.312% (95.728%)\n",
      "Epoch: [33][300/391]\tTime 0.023 (0.023)\tData 0.001 (0.002)\tLoss 0.1571 (0.1289)\tPrec 95.312% (95.632%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.166 (0.166)\tLoss 0.2216 (0.2216)\tPrec 92.188% (92.188%)\n",
      " * Prec 90.450% \n",
      "best acc: 90.740000\n",
      "Epoch: [34][0/391]\tTime 0.119 (0.119)\tData 0.100 (0.100)\tLoss 0.1374 (0.1374)\tPrec 95.312% (95.312%)\n",
      "Epoch: [34][100/391]\tTime 0.020 (0.022)\tData 0.001 (0.002)\tLoss 0.1054 (0.1144)\tPrec 94.531% (95.908%)\n",
      "Epoch: [34][200/391]\tTime 0.023 (0.022)\tData 0.001 (0.002)\tLoss 0.1741 (0.1199)\tPrec 93.750% (95.798%)\n",
      "Epoch: [34][300/391]\tTime 0.023 (0.023)\tData 0.001 (0.002)\tLoss 0.1459 (0.1242)\tPrec 94.531% (95.689%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.094 (0.094)\tLoss 0.2243 (0.2243)\tPrec 92.969% (92.969%)\n",
      " * Prec 90.450% \n",
      "best acc: 90.740000\n",
      "Epoch: [35][0/391]\tTime 0.204 (0.204)\tData 0.179 (0.179)\tLoss 0.0940 (0.0940)\tPrec 96.094% (96.094%)\n",
      "Epoch: [35][100/391]\tTime 0.022 (0.024)\tData 0.001 (0.003)\tLoss 0.0706 (0.1103)\tPrec 96.094% (96.171%)\n",
      "Epoch: [35][200/391]\tTime 0.021 (0.023)\tData 0.001 (0.002)\tLoss 0.1407 (0.1116)\tPrec 93.750% (96.109%)\n",
      "Epoch: [35][300/391]\tTime 0.022 (0.022)\tData 0.001 (0.002)\tLoss 0.1665 (0.1141)\tPrec 93.750% (96.086%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.128 (0.128)\tLoss 0.2605 (0.2605)\tPrec 92.969% (92.969%)\n",
      " * Prec 89.840% \n",
      "best acc: 90.740000\n",
      "Epoch: [36][0/391]\tTime 0.207 (0.207)\tData 0.185 (0.185)\tLoss 0.0811 (0.0811)\tPrec 98.438% (98.438%)\n",
      "Epoch: [36][100/391]\tTime 0.022 (0.025)\tData 0.001 (0.003)\tLoss 0.0795 (0.1156)\tPrec 96.875% (96.001%)\n",
      "Epoch: [36][200/391]\tTime 0.023 (0.024)\tData 0.001 (0.002)\tLoss 0.1058 (0.1132)\tPrec 96.094% (96.117%)\n",
      "Epoch: [36][300/391]\tTime 0.023 (0.023)\tData 0.001 (0.002)\tLoss 0.1437 (0.1128)\tPrec 95.312% (96.065%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.110 (0.110)\tLoss 0.1989 (0.1989)\tPrec 94.531% (94.531%)\n",
      " * Prec 90.240% \n",
      "best acc: 90.740000\n",
      "Epoch: [37][0/391]\tTime 0.126 (0.126)\tData 0.107 (0.107)\tLoss 0.1248 (0.1248)\tPrec 96.094% (96.094%)\n",
      "Epoch: [37][100/391]\tTime 0.023 (0.024)\tData 0.001 (0.002)\tLoss 0.0975 (0.1094)\tPrec 96.875% (96.287%)\n",
      "Epoch: [37][200/391]\tTime 0.023 (0.023)\tData 0.002 (0.002)\tLoss 0.0866 (0.1074)\tPrec 96.875% (96.346%)\n",
      "Epoch: [37][300/391]\tTime 0.023 (0.023)\tData 0.001 (0.002)\tLoss 0.0988 (0.1090)\tPrec 96.875% (96.283%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.151 (0.151)\tLoss 0.2609 (0.2609)\tPrec 92.188% (92.188%)\n",
      " * Prec 90.290% \n",
      "best acc: 90.740000\n",
      "Epoch: [38][0/391]\tTime 0.193 (0.193)\tData 0.174 (0.174)\tLoss 0.0954 (0.0954)\tPrec 97.656% (97.656%)\n",
      "Epoch: [38][100/391]\tTime 0.027 (0.026)\tData 0.002 (0.003)\tLoss 0.0658 (0.0951)\tPrec 97.656% (96.682%)\n",
      "Epoch: [38][200/391]\tTime 0.025 (0.025)\tData 0.002 (0.003)\tLoss 0.1003 (0.1008)\tPrec 95.312% (96.514%)\n",
      "Epoch: [38][300/391]\tTime 0.025 (0.025)\tData 0.002 (0.002)\tLoss 0.0959 (0.1037)\tPrec 97.656% (96.397%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.097 (0.097)\tLoss 0.2308 (0.2308)\tPrec 92.969% (92.969%)\n",
      " * Prec 90.500% \n",
      "best acc: 90.740000\n",
      "Epoch: [39][0/391]\tTime 0.135 (0.135)\tData 0.116 (0.116)\tLoss 0.1132 (0.1132)\tPrec 95.312% (95.312%)\n",
      "Epoch: [39][100/391]\tTime 0.021 (0.023)\tData 0.001 (0.002)\tLoss 0.0573 (0.0986)\tPrec 96.875% (96.473%)\n",
      "Epoch: [39][200/391]\tTime 0.021 (0.022)\tData 0.001 (0.002)\tLoss 0.0748 (0.0986)\tPrec 96.094% (96.572%)\n",
      "Epoch: [39][300/391]\tTime 0.021 (0.022)\tData 0.001 (0.002)\tLoss 0.1646 (0.0983)\tPrec 95.312% (96.610%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.103 (0.103)\tLoss 0.2365 (0.2365)\tPrec 92.188% (92.188%)\n",
      " * Prec 90.080% \n",
      "best acc: 90.740000\n",
      "Epoch: [40][0/391]\tTime 0.197 (0.197)\tData 0.169 (0.169)\tLoss 0.0612 (0.0612)\tPrec 97.656% (97.656%)\n",
      "Epoch: [40][100/391]\tTime 0.023 (0.025)\tData 0.001 (0.003)\tLoss 0.1055 (0.0934)\tPrec 96.875% (96.821%)\n",
      "Epoch: [40][200/391]\tTime 0.025 (0.024)\tData 0.001 (0.002)\tLoss 0.1316 (0.0968)\tPrec 94.531% (96.755%)\n",
      "Epoch: [40][300/391]\tTime 0.020 (0.023)\tData 0.001 (0.002)\tLoss 0.0533 (0.0978)\tPrec 97.656% (96.652%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.090 (0.090)\tLoss 0.2059 (0.2059)\tPrec 94.531% (94.531%)\n",
      " * Prec 90.420% \n",
      "best acc: 90.740000\n",
      "Epoch: [41][0/391]\tTime 0.206 (0.206)\tData 0.186 (0.186)\tLoss 0.1365 (0.1365)\tPrec 96.875% (96.875%)\n",
      "Epoch: [41][100/391]\tTime 0.023 (0.024)\tData 0.001 (0.003)\tLoss 0.0356 (0.0981)\tPrec 99.219% (96.627%)\n",
      "Epoch: [41][200/391]\tTime 0.023 (0.024)\tData 0.001 (0.002)\tLoss 0.0564 (0.0946)\tPrec 97.656% (96.774%)\n",
      "Epoch: [41][300/391]\tTime 0.021 (0.023)\tData 0.001 (0.002)\tLoss 0.1315 (0.0943)\tPrec 96.094% (96.836%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.121 (0.121)\tLoss 0.2663 (0.2663)\tPrec 92.188% (92.188%)\n",
      " * Prec 90.470% \n",
      "best acc: 90.740000\n",
      "Epoch: [42][0/391]\tTime 0.189 (0.189)\tData 0.170 (0.170)\tLoss 0.1087 (0.1087)\tPrec 98.438% (98.438%)\n",
      "Epoch: [42][100/391]\tTime 0.021 (0.022)\tData 0.001 (0.003)\tLoss 0.1389 (0.0816)\tPrec 95.312% (97.316%)\n",
      "Epoch: [42][200/391]\tTime 0.020 (0.021)\tData 0.001 (0.002)\tLoss 0.0649 (0.0855)\tPrec 96.875% (97.143%)\n",
      "Epoch: [42][300/391]\tTime 0.020 (0.021)\tData 0.001 (0.002)\tLoss 0.0458 (0.0888)\tPrec 97.656% (97.028%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.142 (0.142)\tLoss 0.2098 (0.2098)\tPrec 93.750% (93.750%)\n",
      " * Prec 90.170% \n",
      "best acc: 90.740000\n",
      "Epoch: [43][0/391]\tTime 0.210 (0.210)\tData 0.190 (0.190)\tLoss 0.1149 (0.1149)\tPrec 96.094% (96.094%)\n",
      "Epoch: [43][100/391]\tTime 0.026 (0.026)\tData 0.002 (0.003)\tLoss 0.0704 (0.0872)\tPrec 96.875% (96.836%)\n",
      "Epoch: [43][200/391]\tTime 0.026 (0.026)\tData 0.002 (0.003)\tLoss 0.1269 (0.0920)\tPrec 95.312% (96.751%)\n",
      "Epoch: [43][300/391]\tTime 0.026 (0.026)\tData 0.002 (0.002)\tLoss 0.0852 (0.0926)\tPrec 98.438% (96.730%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.114 (0.114)\tLoss 0.2839 (0.2839)\tPrec 91.406% (91.406%)\n",
      " * Prec 90.440% \n",
      "best acc: 90.740000\n",
      "Epoch: [44][0/391]\tTime 0.119 (0.119)\tData 0.101 (0.101)\tLoss 0.1454 (0.1454)\tPrec 93.750% (93.750%)\n",
      "Epoch: [44][100/391]\tTime 0.021 (0.021)\tData 0.001 (0.002)\tLoss 0.1262 (0.0837)\tPrec 93.750% (97.053%)\n",
      "Epoch: [44][200/391]\tTime 0.021 (0.021)\tData 0.001 (0.002)\tLoss 0.0764 (0.0857)\tPrec 97.656% (97.062%)\n",
      "Epoch: [44][300/391]\tTime 0.020 (0.021)\tData 0.001 (0.001)\tLoss 0.0590 (0.0863)\tPrec 96.875% (97.083%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.164 (0.164)\tLoss 0.1923 (0.1923)\tPrec 92.188% (92.188%)\n",
      " * Prec 90.090% \n",
      "best acc: 90.740000\n",
      "Epoch: [45][0/391]\tTime 0.130 (0.130)\tData 0.109 (0.109)\tLoss 0.0834 (0.0834)\tPrec 98.438% (98.438%)\n",
      "Epoch: [45][100/391]\tTime 0.023 (0.024)\tData 0.001 (0.002)\tLoss 0.0906 (0.0701)\tPrec 96.875% (97.687%)\n",
      "Epoch: [45][200/391]\tTime 0.022 (0.023)\tData 0.001 (0.002)\tLoss 0.0536 (0.0720)\tPrec 97.656% (97.613%)\n",
      "Epoch: [45][300/391]\tTime 0.024 (0.023)\tData 0.001 (0.002)\tLoss 0.0884 (0.0717)\tPrec 97.656% (97.591%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.083 (0.083)\tLoss 0.2324 (0.2324)\tPrec 93.750% (93.750%)\n",
      " * Prec 90.820% \n",
      "best acc: 90.820000\n",
      "Epoch: [46][0/391]\tTime 0.150 (0.150)\tData 0.130 (0.130)\tLoss 0.0106 (0.0106)\tPrec 100.000% (100.000%)\n",
      "Epoch: [46][100/391]\tTime 0.023 (0.024)\tData 0.001 (0.002)\tLoss 0.0604 (0.0614)\tPrec 96.875% (97.958%)\n",
      "Epoch: [46][200/391]\tTime 0.023 (0.024)\tData 0.001 (0.002)\tLoss 0.1080 (0.0649)\tPrec 96.875% (97.788%)\n",
      "Epoch: [46][300/391]\tTime 0.023 (0.023)\tData 0.001 (0.002)\tLoss 0.0481 (0.0648)\tPrec 97.656% (97.828%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.161 (0.161)\tLoss 0.2031 (0.2031)\tPrec 95.312% (95.312%)\n",
      " * Prec 91.030% \n",
      "best acc: 91.030000\n",
      "Epoch: [47][0/391]\tTime 0.155 (0.155)\tData 0.136 (0.136)\tLoss 0.0166 (0.0166)\tPrec 100.000% (100.000%)\n",
      "Epoch: [47][100/391]\tTime 0.023 (0.023)\tData 0.001 (0.003)\tLoss 0.0129 (0.0543)\tPrec 100.000% (98.074%)\n",
      "Epoch: [47][200/391]\tTime 0.023 (0.022)\tData 0.001 (0.002)\tLoss 0.1010 (0.0575)\tPrec 96.875% (98.025%)\n",
      "Epoch: [47][300/391]\tTime 0.023 (0.022)\tData 0.001 (0.002)\tLoss 0.0517 (0.0598)\tPrec 98.438% (97.955%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.112 (0.112)\tLoss 0.2015 (0.2015)\tPrec 93.750% (93.750%)\n",
      " * Prec 91.110% \n",
      "best acc: 91.110000\n",
      "Epoch: [48][0/391]\tTime 0.161 (0.161)\tData 0.142 (0.142)\tLoss 0.0610 (0.0610)\tPrec 97.656% (97.656%)\n",
      "Epoch: [48][100/391]\tTime 0.023 (0.023)\tData 0.001 (0.003)\tLoss 0.0479 (0.0600)\tPrec 97.656% (98.012%)\n",
      "Epoch: [48][200/391]\tTime 0.022 (0.023)\tData 0.001 (0.002)\tLoss 0.0349 (0.0568)\tPrec 97.656% (98.103%)\n",
      "Epoch: [48][300/391]\tTime 0.022 (0.022)\tData 0.001 (0.002)\tLoss 0.0833 (0.0590)\tPrec 95.312% (98.017%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.178 (0.178)\tLoss 0.2221 (0.2221)\tPrec 94.531% (94.531%)\n",
      " * Prec 91.130% \n",
      "best acc: 91.130000\n",
      "Epoch: [49][0/391]\tTime 0.159 (0.159)\tData 0.139 (0.139)\tLoss 0.0621 (0.0621)\tPrec 96.875% (96.875%)\n",
      "Epoch: [49][100/391]\tTime 0.020 (0.022)\tData 0.001 (0.003)\tLoss 0.1081 (0.0573)\tPrec 95.312% (98.082%)\n",
      "Epoch: [49][200/391]\tTime 0.018 (0.022)\tData 0.001 (0.002)\tLoss 0.1429 (0.0567)\tPrec 97.656% (98.134%)\n",
      "Epoch: [49][300/391]\tTime 0.019 (0.021)\tData 0.001 (0.002)\tLoss 0.0677 (0.0569)\tPrec 97.656% (98.123%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.110 (0.110)\tLoss 0.2279 (0.2279)\tPrec 92.188% (92.188%)\n",
      " * Prec 91.180% \n",
      "best acc: 91.180000\n",
      "Epoch: [50][0/391]\tTime 0.141 (0.141)\tData 0.121 (0.121)\tLoss 0.0262 (0.0262)\tPrec 99.219% (99.219%)\n",
      "Epoch: [50][100/391]\tTime 0.023 (0.022)\tData 0.001 (0.002)\tLoss 0.0819 (0.0474)\tPrec 98.438% (98.476%)\n",
      "Epoch: [50][200/391]\tTime 0.024 (0.022)\tData 0.001 (0.002)\tLoss 0.0144 (0.0504)\tPrec 100.000% (98.333%)\n",
      "Epoch: [50][300/391]\tTime 0.024 (0.021)\tData 0.001 (0.002)\tLoss 0.0332 (0.0512)\tPrec 97.656% (98.305%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.138 (0.138)\tLoss 0.2320 (0.2320)\tPrec 91.406% (91.406%)\n",
      " * Prec 91.050% \n",
      "best acc: 91.180000\n",
      "Epoch: [51][0/391]\tTime 0.163 (0.163)\tData 0.112 (0.112)\tLoss 0.0492 (0.0492)\tPrec 98.438% (98.438%)\n",
      "Epoch: [51][100/391]\tTime 0.024 (0.026)\tData 0.001 (0.003)\tLoss 0.0174 (0.0548)\tPrec 100.000% (98.198%)\n",
      "Epoch: [51][200/391]\tTime 0.025 (0.025)\tData 0.002 (0.002)\tLoss 0.0850 (0.0561)\tPrec 98.438% (98.189%)\n",
      "Epoch: [51][300/391]\tTime 0.026 (0.025)\tData 0.002 (0.002)\tLoss 0.0345 (0.0554)\tPrec 98.438% (98.201%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.091 (0.091)\tLoss 0.1997 (0.1997)\tPrec 93.750% (93.750%)\n",
      " * Prec 91.120% \n",
      "best acc: 91.180000\n",
      "Epoch: [52][0/391]\tTime 0.130 (0.130)\tData 0.111 (0.111)\tLoss 0.0814 (0.0814)\tPrec 97.656% (97.656%)\n",
      "Epoch: [52][100/391]\tTime 0.022 (0.022)\tData 0.001 (0.002)\tLoss 0.0790 (0.0521)\tPrec 98.438% (98.283%)\n",
      "Epoch: [52][200/391]\tTime 0.021 (0.022)\tData 0.002 (0.002)\tLoss 0.0139 (0.0496)\tPrec 100.000% (98.375%)\n",
      "Epoch: [52][300/391]\tTime 0.023 (0.021)\tData 0.001 (0.002)\tLoss 0.0285 (0.0506)\tPrec 100.000% (98.303%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.149 (0.149)\tLoss 0.1976 (0.1976)\tPrec 94.531% (94.531%)\n",
      " * Prec 90.980% \n",
      "best acc: 91.180000\n",
      "Epoch: [53][0/391]\tTime 0.197 (0.197)\tData 0.178 (0.178)\tLoss 0.0442 (0.0442)\tPrec 98.438% (98.438%)\n",
      "Epoch: [53][100/391]\tTime 0.022 (0.024)\tData 0.001 (0.003)\tLoss 0.0416 (0.0512)\tPrec 98.438% (98.291%)\n",
      "Epoch: [53][200/391]\tTime 0.022 (0.023)\tData 0.001 (0.002)\tLoss 0.0925 (0.0502)\tPrec 97.656% (98.278%)\n",
      "Epoch: [53][300/391]\tTime 0.021 (0.022)\tData 0.001 (0.002)\tLoss 0.0964 (0.0506)\tPrec 96.875% (98.303%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.159 (0.159)\tLoss 0.2128 (0.2128)\tPrec 94.531% (94.531%)\n",
      " * Prec 91.240% \n",
      "best acc: 91.240000\n",
      "Epoch: [54][0/391]\tTime 0.150 (0.150)\tData 0.130 (0.130)\tLoss 0.0772 (0.0772)\tPrec 96.875% (96.875%)\n",
      "Epoch: [54][100/391]\tTime 0.021 (0.023)\tData 0.001 (0.003)\tLoss 0.0476 (0.0489)\tPrec 96.875% (98.368%)\n",
      "Epoch: [54][200/391]\tTime 0.025 (0.023)\tData 0.002 (0.002)\tLoss 0.1009 (0.0496)\tPrec 95.312% (98.344%)\n",
      "Epoch: [54][300/391]\tTime 0.026 (0.024)\tData 0.002 (0.002)\tLoss 0.0489 (0.0486)\tPrec 99.219% (98.396%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.094 (0.094)\tLoss 0.2093 (0.2093)\tPrec 93.750% (93.750%)\n",
      " * Prec 91.120% \n",
      "best acc: 91.240000\n",
      "Epoch: [55][0/391]\tTime 0.144 (0.144)\tData 0.125 (0.125)\tLoss 0.0308 (0.0308)\tPrec 98.438% (98.438%)\n",
      "Epoch: [55][100/391]\tTime 0.022 (0.022)\tData 0.001 (0.002)\tLoss 0.0242 (0.0508)\tPrec 99.219% (98.205%)\n",
      "Epoch: [55][200/391]\tTime 0.023 (0.022)\tData 0.001 (0.002)\tLoss 0.0471 (0.0496)\tPrec 97.656% (98.309%)\n",
      "Epoch: [55][300/391]\tTime 0.023 (0.023)\tData 0.001 (0.002)\tLoss 0.0309 (0.0481)\tPrec 98.438% (98.344%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.140 (0.140)\tLoss 0.2470 (0.2470)\tPrec 92.188% (92.188%)\n",
      " * Prec 91.120% \n",
      "best acc: 91.240000\n",
      "Epoch: [56][0/391]\tTime 0.120 (0.120)\tData 0.101 (0.101)\tLoss 0.0803 (0.0803)\tPrec 97.656% (97.656%)\n",
      "Epoch: [56][100/391]\tTime 0.020 (0.021)\tData 0.001 (0.002)\tLoss 0.0666 (0.0462)\tPrec 98.438% (98.499%)\n",
      "Epoch: [56][200/391]\tTime 0.022 (0.021)\tData 0.001 (0.002)\tLoss 0.0255 (0.0467)\tPrec 98.438% (98.445%)\n",
      "Epoch: [56][300/391]\tTime 0.023 (0.022)\tData 0.001 (0.001)\tLoss 0.0159 (0.0466)\tPrec 100.000% (98.456%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.148 (0.148)\tLoss 0.2165 (0.2165)\tPrec 93.750% (93.750%)\n",
      " * Prec 90.930% \n",
      "best acc: 91.240000\n",
      "Epoch: [57][0/391]\tTime 0.130 (0.130)\tData 0.109 (0.109)\tLoss 0.0464 (0.0464)\tPrec 98.438% (98.438%)\n",
      "Epoch: [57][100/391]\tTime 0.021 (0.023)\tData 0.001 (0.002)\tLoss 0.0663 (0.0505)\tPrec 96.875% (98.159%)\n",
      "Epoch: [57][200/391]\tTime 0.020 (0.022)\tData 0.001 (0.002)\tLoss 0.0796 (0.0470)\tPrec 97.656% (98.403%)\n",
      "Epoch: [57][300/391]\tTime 0.021 (0.022)\tData 0.001 (0.002)\tLoss 0.0331 (0.0467)\tPrec 99.219% (98.409%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.090 (0.090)\tLoss 0.2060 (0.2060)\tPrec 94.531% (94.531%)\n",
      " * Prec 90.890% \n",
      "best acc: 91.240000\n",
      "Epoch: [58][0/391]\tTime 0.191 (0.191)\tData 0.165 (0.165)\tLoss 0.0206 (0.0206)\tPrec 99.219% (99.219%)\n",
      "Epoch: [58][100/391]\tTime 0.021 (0.022)\tData 0.001 (0.003)\tLoss 0.0199 (0.0448)\tPrec 100.000% (98.476%)\n",
      "Epoch: [58][200/391]\tTime 0.020 (0.021)\tData 0.001 (0.002)\tLoss 0.1171 (0.0486)\tPrec 96.875% (98.325%)\n",
      "Epoch: [58][300/391]\tTime 0.021 (0.021)\tData 0.001 (0.002)\tLoss 0.0254 (0.0476)\tPrec 98.438% (98.370%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.156 (0.156)\tLoss 0.2012 (0.2012)\tPrec 94.531% (94.531%)\n",
      " * Prec 91.070% \n",
      "best acc: 91.240000\n",
      "Epoch: [59][0/391]\tTime 0.206 (0.206)\tData 0.183 (0.183)\tLoss 0.0160 (0.0160)\tPrec 100.000% (100.000%)\n",
      "Epoch: [59][100/391]\tTime 0.020 (0.022)\tData 0.001 (0.003)\tLoss 0.0645 (0.0409)\tPrec 96.875% (98.569%)\n",
      "Epoch: [59][200/391]\tTime 0.021 (0.021)\tData 0.001 (0.002)\tLoss 0.0508 (0.0432)\tPrec 99.219% (98.465%)\n",
      "Epoch: [59][300/391]\tTime 0.021 (0.021)\tData 0.001 (0.002)\tLoss 0.0282 (0.0443)\tPrec 99.219% (98.453%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.140 (0.140)\tLoss 0.1894 (0.1894)\tPrec 93.750% (93.750%)\n",
      " * Prec 90.980% \n",
      "best acc: 91.240000\n",
      "Epoch: [60][0/391]\tTime 0.194 (0.194)\tData 0.175 (0.175)\tLoss 0.0890 (0.0890)\tPrec 97.656% (97.656%)\n",
      "Epoch: [60][100/391]\tTime 0.019 (0.023)\tData 0.001 (0.003)\tLoss 0.0570 (0.0431)\tPrec 98.438% (98.499%)\n",
      "Epoch: [60][200/391]\tTime 0.018 (0.022)\tData 0.001 (0.002)\tLoss 0.0572 (0.0458)\tPrec 98.438% (98.469%)\n",
      "Epoch: [60][300/391]\tTime 0.019 (0.022)\tData 0.001 (0.002)\tLoss 0.0476 (0.0448)\tPrec 98.438% (98.526%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.092 (0.092)\tLoss 0.2275 (0.2275)\tPrec 94.531% (94.531%)\n",
      " * Prec 90.950% \n",
      "best acc: 91.240000\n",
      "Epoch: [61][0/391]\tTime 0.197 (0.197)\tData 0.175 (0.175)\tLoss 0.0269 (0.0269)\tPrec 99.219% (99.219%)\n",
      "Epoch: [61][100/391]\tTime 0.026 (0.025)\tData 0.002 (0.003)\tLoss 0.0777 (0.0450)\tPrec 96.875% (98.499%)\n",
      "Epoch: [61][200/391]\tTime 0.023 (0.024)\tData 0.001 (0.002)\tLoss 0.0231 (0.0465)\tPrec 99.219% (98.449%)\n",
      "Epoch: [61][300/391]\tTime 0.023 (0.024)\tData 0.001 (0.002)\tLoss 0.0601 (0.0459)\tPrec 98.438% (98.450%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.102 (0.102)\tLoss 0.2088 (0.2088)\tPrec 91.406% (91.406%)\n",
      " * Prec 90.940% \n",
      "best acc: 91.240000\n",
      "Epoch: [62][0/391]\tTime 0.162 (0.162)\tData 0.104 (0.104)\tLoss 0.0498 (0.0498)\tPrec 99.219% (99.219%)\n",
      "Epoch: [62][100/391]\tTime 0.022 (0.024)\tData 0.001 (0.002)\tLoss 0.0343 (0.0446)\tPrec 99.219% (98.592%)\n",
      "Epoch: [62][200/391]\tTime 0.022 (0.023)\tData 0.001 (0.002)\tLoss 0.0178 (0.0434)\tPrec 100.000% (98.577%)\n",
      "Epoch: [62][300/391]\tTime 0.022 (0.023)\tData 0.001 (0.002)\tLoss 0.0427 (0.0436)\tPrec 98.438% (98.593%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.136 (0.136)\tLoss 0.2338 (0.2338)\tPrec 93.750% (93.750%)\n",
      " * Prec 91.100% \n",
      "best acc: 91.240000\n",
      "Epoch: [63][0/391]\tTime 0.208 (0.208)\tData 0.188 (0.188)\tLoss 0.0624 (0.0624)\tPrec 98.438% (98.438%)\n",
      "Epoch: [63][100/391]\tTime 0.019 (0.023)\tData 0.001 (0.003)\tLoss 0.0335 (0.0406)\tPrec 98.438% (98.507%)\n",
      "Epoch: [63][200/391]\tTime 0.019 (0.022)\tData 0.001 (0.002)\tLoss 0.0931 (0.0446)\tPrec 96.094% (98.469%)\n",
      "Epoch: [63][300/391]\tTime 0.019 (0.022)\tData 0.001 (0.002)\tLoss 0.0529 (0.0439)\tPrec 98.438% (98.500%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.110 (0.110)\tLoss 0.2756 (0.2756)\tPrec 93.750% (93.750%)\n",
      " * Prec 90.940% \n",
      "best acc: 91.240000\n",
      "Epoch: [64][0/391]\tTime 0.119 (0.119)\tData 0.100 (0.100)\tLoss 0.0284 (0.0284)\tPrec 99.219% (99.219%)\n",
      "Epoch: [64][100/391]\tTime 0.023 (0.024)\tData 0.001 (0.002)\tLoss 0.0671 (0.0427)\tPrec 98.438% (98.515%)\n",
      "Epoch: [64][200/391]\tTime 0.021 (0.023)\tData 0.001 (0.002)\tLoss 0.0471 (0.0434)\tPrec 96.875% (98.523%)\n",
      "Epoch: [64][300/391]\tTime 0.022 (0.023)\tData 0.001 (0.002)\tLoss 0.0318 (0.0411)\tPrec 99.219% (98.596%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.108 (0.108)\tLoss 0.2360 (0.2360)\tPrec 93.750% (93.750%)\n",
      " * Prec 91.090% \n",
      "best acc: 91.240000\n",
      "Epoch: [65][0/391]\tTime 0.198 (0.198)\tData 0.173 (0.173)\tLoss 0.0093 (0.0093)\tPrec 100.000% (100.000%)\n",
      "Epoch: [65][100/391]\tTime 0.021 (0.022)\tData 0.001 (0.003)\tLoss 0.0277 (0.0408)\tPrec 99.219% (98.577%)\n",
      "Epoch: [65][200/391]\tTime 0.020 (0.021)\tData 0.001 (0.002)\tLoss 0.0355 (0.0407)\tPrec 98.438% (98.628%)\n",
      "Epoch: [65][300/391]\tTime 0.020 (0.021)\tData 0.001 (0.002)\tLoss 0.0174 (0.0405)\tPrec 100.000% (98.643%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.135 (0.135)\tLoss 0.2391 (0.2391)\tPrec 92.969% (92.969%)\n",
      " * Prec 91.370% \n",
      "best acc: 91.370000\n",
      "Epoch: [66][0/391]\tTime 0.125 (0.125)\tData 0.106 (0.106)\tLoss 0.0474 (0.0474)\tPrec 98.438% (98.438%)\n",
      "Epoch: [66][100/391]\tTime 0.020 (0.022)\tData 0.001 (0.002)\tLoss 0.0686 (0.0383)\tPrec 96.094% (98.600%)\n",
      "Epoch: [66][200/391]\tTime 0.022 (0.021)\tData 0.001 (0.002)\tLoss 0.0800 (0.0397)\tPrec 98.438% (98.620%)\n",
      "Epoch: [66][300/391]\tTime 0.020 (0.021)\tData 0.001 (0.002)\tLoss 0.0302 (0.0404)\tPrec 98.438% (98.583%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.118 (0.118)\tLoss 0.2466 (0.2466)\tPrec 92.188% (92.188%)\n",
      " * Prec 91.020% \n",
      "best acc: 91.370000\n",
      "Epoch: [67][0/391]\tTime 0.209 (0.209)\tData 0.186 (0.186)\tLoss 0.0166 (0.0166)\tPrec 99.219% (99.219%)\n",
      "Epoch: [67][100/391]\tTime 0.021 (0.023)\tData 0.001 (0.003)\tLoss 0.0599 (0.0437)\tPrec 96.094% (98.453%)\n",
      "Epoch: [67][200/391]\tTime 0.021 (0.023)\tData 0.001 (0.002)\tLoss 0.0150 (0.0413)\tPrec 100.000% (98.546%)\n",
      "Epoch: [67][300/391]\tTime 0.021 (0.022)\tData 0.001 (0.002)\tLoss 0.1612 (0.0409)\tPrec 95.312% (98.596%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.095 (0.095)\tLoss 0.2967 (0.2967)\tPrec 92.188% (92.188%)\n",
      " * Prec 91.040% \n",
      "best acc: 91.370000\n",
      "Epoch: [68][0/391]\tTime 0.199 (0.199)\tData 0.180 (0.180)\tLoss 0.0301 (0.0301)\tPrec 97.656% (97.656%)\n",
      "Epoch: [68][100/391]\tTime 0.023 (0.025)\tData 0.001 (0.003)\tLoss 0.0180 (0.0376)\tPrec 100.000% (98.762%)\n",
      "Epoch: [68][200/391]\tTime 0.023 (0.024)\tData 0.001 (0.002)\tLoss 0.0227 (0.0388)\tPrec 99.219% (98.682%)\n",
      "Epoch: [68][300/391]\tTime 0.023 (0.024)\tData 0.001 (0.002)\tLoss 0.0454 (0.0396)\tPrec 98.438% (98.656%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.111 (0.111)\tLoss 0.2569 (0.2569)\tPrec 92.969% (92.969%)\n",
      " * Prec 91.270% \n",
      "best acc: 91.370000\n",
      "Epoch: [69][0/391]\tTime 0.148 (0.148)\tData 0.129 (0.129)\tLoss 0.0457 (0.0457)\tPrec 99.219% (99.219%)\n",
      "Epoch: [69][100/391]\tTime 0.026 (0.025)\tData 0.002 (0.003)\tLoss 0.0109 (0.0373)\tPrec 100.000% (98.731%)\n",
      "Epoch: [69][200/391]\tTime 0.026 (0.025)\tData 0.002 (0.002)\tLoss 0.0647 (0.0391)\tPrec 97.656% (98.686%)\n",
      "Epoch: [69][300/391]\tTime 0.020 (0.025)\tData 0.001 (0.002)\tLoss 0.0206 (0.0391)\tPrec 99.219% (98.679%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.107 (0.107)\tLoss 0.2536 (0.2536)\tPrec 94.531% (94.531%)\n",
      " * Prec 91.100% \n",
      "best acc: 91.370000\n",
      "Epoch: [70][0/391]\tTime 0.200 (0.200)\tData 0.180 (0.180)\tLoss 0.0754 (0.0754)\tPrec 96.875% (96.875%)\n",
      "Epoch: [70][100/391]\tTime 0.023 (0.025)\tData 0.001 (0.003)\tLoss 0.0453 (0.0397)\tPrec 97.656% (98.608%)\n",
      "Epoch: [70][200/391]\tTime 0.022 (0.024)\tData 0.001 (0.002)\tLoss 0.0873 (0.0431)\tPrec 95.312% (98.500%)\n",
      "Epoch: [70][300/391]\tTime 0.022 (0.023)\tData 0.001 (0.002)\tLoss 0.0199 (0.0408)\tPrec 99.219% (98.585%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.120 (0.120)\tLoss 0.2577 (0.2577)\tPrec 92.969% (92.969%)\n",
      " * Prec 91.190% \n",
      "best acc: 91.370000\n",
      "Epoch: [71][0/391]\tTime 0.218 (0.218)\tData 0.191 (0.191)\tLoss 0.0608 (0.0608)\tPrec 99.219% (99.219%)\n",
      "Epoch: [71][100/391]\tTime 0.021 (0.024)\tData 0.001 (0.003)\tLoss 0.0104 (0.0402)\tPrec 100.000% (98.762%)\n",
      "Epoch: [71][200/391]\tTime 0.022 (0.023)\tData 0.001 (0.002)\tLoss 0.0495 (0.0400)\tPrec 98.438% (98.721%)\n",
      "Epoch: [71][300/391]\tTime 0.023 (0.023)\tData 0.001 (0.002)\tLoss 0.0359 (0.0399)\tPrec 99.219% (98.707%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.167 (0.167)\tLoss 0.2451 (0.2451)\tPrec 92.969% (92.969%)\n",
      " * Prec 91.130% \n",
      "best acc: 91.370000\n",
      "Epoch: [72][0/391]\tTime 0.201 (0.201)\tData 0.179 (0.179)\tLoss 0.0244 (0.0244)\tPrec 100.000% (100.000%)\n",
      "Epoch: [72][100/391]\tTime 0.020 (0.023)\tData 0.001 (0.003)\tLoss 0.0158 (0.0366)\tPrec 99.219% (98.801%)\n",
      "Epoch: [72][200/391]\tTime 0.020 (0.022)\tData 0.001 (0.002)\tLoss 0.0236 (0.0392)\tPrec 99.219% (98.702%)\n",
      "Epoch: [72][300/391]\tTime 0.020 (0.021)\tData 0.001 (0.002)\tLoss 0.0167 (0.0392)\tPrec 99.219% (98.726%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.117 (0.117)\tLoss 0.2868 (0.2868)\tPrec 92.188% (92.188%)\n",
      " * Prec 91.020% \n",
      "best acc: 91.370000\n",
      "Epoch: [73][0/391]\tTime 0.129 (0.129)\tData 0.110 (0.110)\tLoss 0.0407 (0.0407)\tPrec 99.219% (99.219%)\n",
      "Epoch: [73][100/391]\tTime 0.023 (0.024)\tData 0.001 (0.002)\tLoss 0.0284 (0.0404)\tPrec 99.219% (98.677%)\n",
      "Epoch: [73][200/391]\tTime 0.025 (0.023)\tData 0.001 (0.002)\tLoss 0.0387 (0.0384)\tPrec 99.219% (98.737%)\n",
      "Epoch: [73][300/391]\tTime 0.023 (0.023)\tData 0.001 (0.002)\tLoss 0.0535 (0.0386)\tPrec 98.438% (98.749%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.136 (0.136)\tLoss 0.2307 (0.2307)\tPrec 93.750% (93.750%)\n",
      " * Prec 91.230% \n",
      "best acc: 91.370000\n",
      "Epoch: [74][0/391]\tTime 0.205 (0.205)\tData 0.187 (0.187)\tLoss 0.0152 (0.0152)\tPrec 100.000% (100.000%)\n",
      "Epoch: [74][100/391]\tTime 0.020 (0.022)\tData 0.001 (0.003)\tLoss 0.0272 (0.0378)\tPrec 99.219% (98.685%)\n",
      "Epoch: [74][200/391]\tTime 0.021 (0.021)\tData 0.001 (0.002)\tLoss 0.0605 (0.0368)\tPrec 99.219% (98.713%)\n",
      "Epoch: [74][300/391]\tTime 0.021 (0.021)\tData 0.001 (0.002)\tLoss 0.0596 (0.0372)\tPrec 97.656% (98.705%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.111 (0.111)\tLoss 0.2846 (0.2846)\tPrec 90.625% (90.625%)\n",
      " * Prec 90.970% \n",
      "best acc: 91.370000\n",
      "Epoch: [75][0/391]\tTime 0.199 (0.199)\tData 0.172 (0.172)\tLoss 0.0124 (0.0124)\tPrec 99.219% (99.219%)\n",
      "Epoch: [75][100/391]\tTime 0.023 (0.025)\tData 0.001 (0.003)\tLoss 0.0383 (0.0406)\tPrec 97.656% (98.623%)\n",
      "Epoch: [75][200/391]\tTime 0.023 (0.024)\tData 0.001 (0.002)\tLoss 0.0031 (0.0400)\tPrec 100.000% (98.655%)\n",
      "Epoch: [75][300/391]\tTime 0.023 (0.024)\tData 0.001 (0.002)\tLoss 0.0277 (0.0394)\tPrec 99.219% (98.692%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.150 (0.150)\tLoss 0.2511 (0.2511)\tPrec 92.188% (92.188%)\n",
      " * Prec 90.920% \n",
      "best acc: 91.370000\n",
      "Epoch: [76][0/391]\tTime 0.156 (0.156)\tData 0.137 (0.137)\tLoss 0.0316 (0.0316)\tPrec 98.438% (98.438%)\n",
      "Epoch: [76][100/391]\tTime 0.023 (0.024)\tData 0.001 (0.003)\tLoss 0.0327 (0.0395)\tPrec 99.219% (98.739%)\n",
      "Epoch: [76][200/391]\tTime 0.023 (0.024)\tData 0.001 (0.002)\tLoss 0.0489 (0.0390)\tPrec 97.656% (98.721%)\n",
      "Epoch: [76][300/391]\tTime 0.023 (0.024)\tData 0.001 (0.002)\tLoss 0.0266 (0.0376)\tPrec 99.219% (98.759%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.096 (0.096)\tLoss 0.2349 (0.2349)\tPrec 93.750% (93.750%)\n",
      " * Prec 90.800% \n",
      "best acc: 91.370000\n",
      "Epoch: [77][0/391]\tTime 0.126 (0.126)\tData 0.107 (0.107)\tLoss 0.0076 (0.0076)\tPrec 100.000% (100.000%)\n",
      "Epoch: [77][100/391]\tTime 0.018 (0.022)\tData 0.001 (0.002)\tLoss 0.0225 (0.0434)\tPrec 100.000% (98.546%)\n",
      "Epoch: [77][200/391]\tTime 0.021 (0.021)\tData 0.001 (0.002)\tLoss 0.0218 (0.0418)\tPrec 99.219% (98.597%)\n",
      "Epoch: [77][300/391]\tTime 0.020 (0.021)\tData 0.002 (0.002)\tLoss 0.0410 (0.0415)\tPrec 98.438% (98.617%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.090 (0.090)\tLoss 0.2188 (0.2188)\tPrec 92.188% (92.188%)\n",
      " * Prec 91.060% \n",
      "best acc: 91.370000\n",
      "Epoch: [78][0/391]\tTime 0.161 (0.161)\tData 0.142 (0.142)\tLoss 0.0191 (0.0191)\tPrec 100.000% (100.000%)\n",
      "Epoch: [78][100/391]\tTime 0.023 (0.024)\tData 0.001 (0.003)\tLoss 0.0159 (0.0389)\tPrec 100.000% (98.546%)\n",
      "Epoch: [78][200/391]\tTime 0.023 (0.024)\tData 0.001 (0.002)\tLoss 0.0333 (0.0377)\tPrec 98.438% (98.675%)\n",
      "Epoch: [78][300/391]\tTime 0.023 (0.023)\tData 0.001 (0.002)\tLoss 0.0216 (0.0375)\tPrec 100.000% (98.697%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.084 (0.084)\tLoss 0.2542 (0.2542)\tPrec 92.188% (92.188%)\n",
      " * Prec 91.180% \n",
      "best acc: 91.370000\n",
      "Epoch: [79][0/391]\tTime 0.198 (0.198)\tData 0.180 (0.180)\tLoss 0.0297 (0.0297)\tPrec 99.219% (99.219%)\n",
      "Epoch: [79][100/391]\tTime 0.021 (0.022)\tData 0.001 (0.003)\tLoss 0.0187 (0.0346)\tPrec 99.219% (98.886%)\n",
      "Epoch: [79][200/391]\tTime 0.021 (0.021)\tData 0.001 (0.002)\tLoss 0.0149 (0.0354)\tPrec 99.219% (98.822%)\n",
      "Epoch: [79][300/391]\tTime 0.019 (0.021)\tData 0.001 (0.002)\tLoss 0.0096 (0.0362)\tPrec 100.000% (98.803%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.124 (0.124)\tLoss 0.2524 (0.2524)\tPrec 92.188% (92.188%)\n",
      " * Prec 91.180% \n",
      "best acc: 91.370000\n",
      "Epoch: [80][0/391]\tTime 0.122 (0.122)\tData 0.102 (0.102)\tLoss 0.0516 (0.0516)\tPrec 98.438% (98.438%)\n",
      "Epoch: [80][100/391]\tTime 0.023 (0.024)\tData 0.001 (0.002)\tLoss 0.0253 (0.0394)\tPrec 99.219% (98.731%)\n",
      "Epoch: [80][200/391]\tTime 0.023 (0.023)\tData 0.001 (0.002)\tLoss 0.0637 (0.0379)\tPrec 96.094% (98.721%)\n",
      "Epoch: [80][300/391]\tTime 0.023 (0.023)\tData 0.001 (0.001)\tLoss 0.0317 (0.0375)\tPrec 98.438% (98.728%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.180 (0.180)\tLoss 0.2629 (0.2629)\tPrec 92.969% (92.969%)\n",
      " * Prec 91.040% \n",
      "best acc: 91.370000\n",
      "Epoch: [81][0/391]\tTime 0.134 (0.134)\tData 0.115 (0.115)\tLoss 0.0547 (0.0547)\tPrec 97.656% (97.656%)\n",
      "Epoch: [81][100/391]\tTime 0.019 (0.022)\tData 0.001 (0.002)\tLoss 0.0119 (0.0420)\tPrec 100.000% (98.677%)\n",
      "Epoch: [81][200/391]\tTime 0.019 (0.022)\tData 0.001 (0.002)\tLoss 0.0039 (0.0395)\tPrec 100.000% (98.698%)\n",
      "Epoch: [81][300/391]\tTime 0.019 (0.022)\tData 0.001 (0.002)\tLoss 0.0215 (0.0392)\tPrec 99.219% (98.713%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.092 (0.092)\tLoss 0.2638 (0.2638)\tPrec 92.969% (92.969%)\n",
      " * Prec 91.110% \n",
      "best acc: 91.370000\n",
      "Epoch: [82][0/391]\tTime 0.178 (0.178)\tData 0.154 (0.154)\tLoss 0.0237 (0.0237)\tPrec 99.219% (99.219%)\n",
      "Epoch: [82][100/391]\tTime 0.023 (0.025)\tData 0.001 (0.003)\tLoss 0.0619 (0.0353)\tPrec 98.438% (98.817%)\n",
      "Epoch: [82][200/391]\tTime 0.023 (0.024)\tData 0.001 (0.002)\tLoss 0.0041 (0.0385)\tPrec 100.000% (98.686%)\n",
      "Epoch: [82][300/391]\tTime 0.023 (0.024)\tData 0.001 (0.002)\tLoss 0.0176 (0.0384)\tPrec 99.219% (98.694%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.093 (0.093)\tLoss 0.2269 (0.2269)\tPrec 91.406% (91.406%)\n",
      " * Prec 90.980% \n",
      "best acc: 91.370000\n",
      "Epoch: [83][0/391]\tTime 0.195 (0.195)\tData 0.176 (0.176)\tLoss 0.0553 (0.0553)\tPrec 97.656% (97.656%)\n",
      "Epoch: [83][100/391]\tTime 0.023 (0.024)\tData 0.001 (0.003)\tLoss 0.0393 (0.0394)\tPrec 98.438% (98.716%)\n",
      "Epoch: [83][200/391]\tTime 0.023 (0.023)\tData 0.001 (0.002)\tLoss 0.0859 (0.0410)\tPrec 98.438% (98.616%)\n",
      "Epoch: [83][300/391]\tTime 0.022 (0.023)\tData 0.001 (0.002)\tLoss 0.0446 (0.0390)\tPrec 97.656% (98.671%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.117 (0.117)\tLoss 0.2368 (0.2368)\tPrec 90.625% (90.625%)\n",
      " * Prec 90.870% \n",
      "best acc: 91.370000\n",
      "Epoch: [84][0/391]\tTime 0.139 (0.139)\tData 0.119 (0.119)\tLoss 0.0567 (0.0567)\tPrec 97.656% (97.656%)\n",
      "Epoch: [84][100/391]\tTime 0.022 (0.022)\tData 0.001 (0.002)\tLoss 0.0248 (0.0371)\tPrec 99.219% (98.646%)\n",
      "Epoch: [84][200/391]\tTime 0.021 (0.021)\tData 0.001 (0.002)\tLoss 0.0502 (0.0380)\tPrec 98.438% (98.675%)\n",
      "Epoch: [84][300/391]\tTime 0.021 (0.021)\tData 0.001 (0.002)\tLoss 0.0216 (0.0391)\tPrec 99.219% (98.643%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.085 (0.085)\tLoss 0.2513 (0.2513)\tPrec 92.969% (92.969%)\n",
      " * Prec 90.930% \n",
      "best acc: 91.370000\n",
      "Epoch: [85][0/391]\tTime 0.240 (0.240)\tData 0.182 (0.182)\tLoss 0.0127 (0.0127)\tPrec 100.000% (100.000%)\n",
      "Epoch: [85][100/391]\tTime 0.023 (0.024)\tData 0.001 (0.003)\tLoss 0.0238 (0.0375)\tPrec 100.000% (98.801%)\n",
      "Epoch: [85][200/391]\tTime 0.021 (0.024)\tData 0.001 (0.002)\tLoss 0.0270 (0.0379)\tPrec 98.438% (98.760%)\n",
      "Epoch: [85][300/391]\tTime 0.017 (0.023)\tData 0.001 (0.002)\tLoss 0.0111 (0.0376)\tPrec 100.000% (98.775%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.088 (0.088)\tLoss 0.2279 (0.2279)\tPrec 93.750% (93.750%)\n",
      " * Prec 91.030% \n",
      "best acc: 91.370000\n",
      "Epoch: [86][0/391]\tTime 0.126 (0.126)\tData 0.106 (0.106)\tLoss 0.0561 (0.0561)\tPrec 97.656% (97.656%)\n",
      "Epoch: [86][100/391]\tTime 0.018 (0.022)\tData 0.001 (0.002)\tLoss 0.0408 (0.0379)\tPrec 99.219% (98.693%)\n",
      "Epoch: [86][200/391]\tTime 0.019 (0.022)\tData 0.001 (0.002)\tLoss 0.0570 (0.0387)\tPrec 98.438% (98.675%)\n",
      "Epoch: [86][300/391]\tTime 0.019 (0.021)\tData 0.001 (0.002)\tLoss 0.0461 (0.0382)\tPrec 98.438% (98.684%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.111 (0.111)\tLoss 0.2493 (0.2493)\tPrec 92.188% (92.188%)\n",
      " * Prec 90.940% \n",
      "best acc: 91.370000\n",
      "Epoch: [87][0/391]\tTime 0.130 (0.130)\tData 0.111 (0.111)\tLoss 0.0756 (0.0756)\tPrec 99.219% (99.219%)\n",
      "Epoch: [87][100/391]\tTime 0.022 (0.023)\tData 0.001 (0.002)\tLoss 0.0307 (0.0401)\tPrec 99.219% (98.654%)\n",
      "Epoch: [87][200/391]\tTime 0.022 (0.022)\tData 0.001 (0.002)\tLoss 0.0475 (0.0386)\tPrec 98.438% (98.780%)\n",
      "Epoch: [87][300/391]\tTime 0.022 (0.022)\tData 0.001 (0.002)\tLoss 0.0397 (0.0370)\tPrec 97.656% (98.798%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.095 (0.095)\tLoss 0.2857 (0.2857)\tPrec 91.406% (91.406%)\n",
      " * Prec 90.880% \n",
      "best acc: 91.370000\n",
      "Epoch: [88][0/391]\tTime 0.211 (0.211)\tData 0.191 (0.191)\tLoss 0.0606 (0.0606)\tPrec 98.438% (98.438%)\n",
      "Epoch: [88][100/391]\tTime 0.021 (0.023)\tData 0.001 (0.003)\tLoss 0.0416 (0.0378)\tPrec 97.656% (98.646%)\n",
      "Epoch: [88][200/391]\tTime 0.020 (0.022)\tData 0.001 (0.002)\tLoss 0.0152 (0.0390)\tPrec 100.000% (98.632%)\n",
      "Epoch: [88][300/391]\tTime 0.021 (0.021)\tData 0.001 (0.002)\tLoss 0.0344 (0.0384)\tPrec 99.219% (98.640%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.087 (0.087)\tLoss 0.2740 (0.2740)\tPrec 92.188% (92.188%)\n",
      " * Prec 91.010% \n",
      "best acc: 91.370000\n",
      "Epoch: [89][0/391]\tTime 0.190 (0.190)\tData 0.172 (0.172)\tLoss 0.0533 (0.0533)\tPrec 98.438% (98.438%)\n",
      "Epoch: [89][100/391]\tTime 0.021 (0.022)\tData 0.001 (0.003)\tLoss 0.0697 (0.0349)\tPrec 98.438% (98.786%)\n",
      "Epoch: [89][200/391]\tTime 0.020 (0.021)\tData 0.001 (0.002)\tLoss 0.0100 (0.0354)\tPrec 100.000% (98.861%)\n",
      "Epoch: [89][300/391]\tTime 0.020 (0.021)\tData 0.001 (0.002)\tLoss 0.0595 (0.0349)\tPrec 98.438% (98.861%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.167 (0.167)\tLoss 0.3047 (0.3047)\tPrec 90.625% (90.625%)\n",
      " * Prec 91.020% \n",
      "best acc: 91.370000\n",
      "Epoch: [90][0/391]\tTime 0.175 (0.175)\tData 0.156 (0.156)\tLoss 0.0157 (0.0157)\tPrec 99.219% (99.219%)\n",
      "Epoch: [90][100/391]\tTime 0.020 (0.022)\tData 0.001 (0.003)\tLoss 0.0518 (0.0394)\tPrec 98.438% (98.724%)\n",
      "Epoch: [90][200/391]\tTime 0.021 (0.021)\tData 0.001 (0.002)\tLoss 0.0214 (0.0373)\tPrec 100.000% (98.772%)\n",
      "Epoch: [90][300/391]\tTime 0.020 (0.021)\tData 0.001 (0.002)\tLoss 0.0146 (0.0376)\tPrec 100.000% (98.778%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.121 (0.121)\tLoss 0.2386 (0.2386)\tPrec 92.969% (92.969%)\n",
      " * Prec 91.030% \n",
      "best acc: 91.370000\n",
      "Epoch: [91][0/391]\tTime 0.198 (0.198)\tData 0.175 (0.175)\tLoss 0.0286 (0.0286)\tPrec 99.219% (99.219%)\n",
      "Epoch: [91][100/391]\tTime 0.023 (0.025)\tData 0.001 (0.003)\tLoss 0.0365 (0.0339)\tPrec 99.219% (98.824%)\n",
      "Epoch: [91][200/391]\tTime 0.020 (0.023)\tData 0.001 (0.002)\tLoss 0.0540 (0.0350)\tPrec 98.438% (98.783%)\n",
      "Epoch: [91][300/391]\tTime 0.021 (0.022)\tData 0.001 (0.002)\tLoss 0.0479 (0.0349)\tPrec 98.438% (98.806%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.137 (0.137)\tLoss 0.2286 (0.2286)\tPrec 92.969% (92.969%)\n",
      " * Prec 90.910% \n",
      "best acc: 91.370000\n",
      "Epoch: [92][0/391]\tTime 0.132 (0.132)\tData 0.112 (0.112)\tLoss 0.0171 (0.0171)\tPrec 99.219% (99.219%)\n",
      "Epoch: [92][100/391]\tTime 0.023 (0.024)\tData 0.001 (0.002)\tLoss 0.0531 (0.0372)\tPrec 98.438% (98.778%)\n",
      "Epoch: [92][200/391]\tTime 0.023 (0.024)\tData 0.001 (0.002)\tLoss 0.0277 (0.0376)\tPrec 99.219% (98.783%)\n",
      "Epoch: [92][300/391]\tTime 0.023 (0.023)\tData 0.001 (0.002)\tLoss 0.0241 (0.0379)\tPrec 99.219% (98.749%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.129 (0.129)\tLoss 0.2335 (0.2335)\tPrec 92.188% (92.188%)\n",
      " * Prec 90.980% \n",
      "best acc: 91.370000\n",
      "Epoch: [93][0/391]\tTime 0.128 (0.128)\tData 0.109 (0.109)\tLoss 0.0594 (0.0594)\tPrec 98.438% (98.438%)\n",
      "Epoch: [93][100/391]\tTime 0.020 (0.023)\tData 0.001 (0.002)\tLoss 0.0518 (0.0373)\tPrec 96.875% (98.770%)\n",
      "Epoch: [93][200/391]\tTime 0.021 (0.022)\tData 0.001 (0.002)\tLoss 0.0600 (0.0391)\tPrec 97.656% (98.698%)\n",
      "Epoch: [93][300/391]\tTime 0.021 (0.021)\tData 0.001 (0.002)\tLoss 0.0283 (0.0379)\tPrec 98.438% (98.707%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.083 (0.083)\tLoss 0.2234 (0.2234)\tPrec 92.969% (92.969%)\n",
      " * Prec 91.040% \n",
      "best acc: 91.370000\n",
      "Epoch: [94][0/391]\tTime 0.186 (0.186)\tData 0.166 (0.166)\tLoss 0.0392 (0.0392)\tPrec 98.438% (98.438%)\n",
      "Epoch: [94][100/391]\tTime 0.023 (0.025)\tData 0.001 (0.003)\tLoss 0.0231 (0.0359)\tPrec 99.219% (98.940%)\n",
      "Epoch: [94][200/391]\tTime 0.022 (0.024)\tData 0.001 (0.002)\tLoss 0.1065 (0.0364)\tPrec 96.094% (98.853%)\n",
      "Epoch: [94][300/391]\tTime 0.022 (0.023)\tData 0.001 (0.002)\tLoss 0.0269 (0.0377)\tPrec 99.219% (98.783%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.161 (0.161)\tLoss 0.2220 (0.2220)\tPrec 93.750% (93.750%)\n",
      " * Prec 91.020% \n",
      "best acc: 91.370000\n",
      "Epoch: [95][0/391]\tTime 0.204 (0.204)\tData 0.183 (0.183)\tLoss 0.0367 (0.0367)\tPrec 98.438% (98.438%)\n",
      "Epoch: [95][100/391]\tTime 0.021 (0.022)\tData 0.001 (0.003)\tLoss 0.0205 (0.0353)\tPrec 99.219% (98.840%)\n",
      "Epoch: [95][200/391]\tTime 0.020 (0.021)\tData 0.001 (0.002)\tLoss 0.0521 (0.0371)\tPrec 98.438% (98.764%)\n",
      "Epoch: [95][300/391]\tTime 0.021 (0.021)\tData 0.001 (0.002)\tLoss 0.0845 (0.0369)\tPrec 95.312% (98.752%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.158 (0.158)\tLoss 0.2022 (0.2022)\tPrec 93.750% (93.750%)\n",
      " * Prec 91.010% \n",
      "best acc: 91.370000\n",
      "Epoch: [96][0/391]\tTime 0.138 (0.138)\tData 0.119 (0.119)\tLoss 0.0065 (0.0065)\tPrec 100.000% (100.000%)\n",
      "Epoch: [96][100/391]\tTime 0.023 (0.024)\tData 0.001 (0.002)\tLoss 0.0084 (0.0406)\tPrec 100.000% (98.577%)\n",
      "Epoch: [96][200/391]\tTime 0.020 (0.023)\tData 0.001 (0.002)\tLoss 0.0783 (0.0392)\tPrec 96.875% (98.663%)\n",
      "Epoch: [96][300/391]\tTime 0.020 (0.022)\tData 0.001 (0.002)\tLoss 0.0749 (0.0388)\tPrec 97.656% (98.689%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.092 (0.092)\tLoss 0.2487 (0.2487)\tPrec 92.969% (92.969%)\n",
      " * Prec 91.240% \n",
      "best acc: 91.370000\n",
      "Epoch: [97][0/391]\tTime 0.203 (0.203)\tData 0.184 (0.184)\tLoss 0.0278 (0.0278)\tPrec 99.219% (99.219%)\n",
      "Epoch: [97][100/391]\tTime 0.023 (0.025)\tData 0.001 (0.003)\tLoss 0.0794 (0.0381)\tPrec 97.656% (98.569%)\n",
      "Epoch: [97][200/391]\tTime 0.023 (0.024)\tData 0.001 (0.002)\tLoss 0.0438 (0.0379)\tPrec 98.438% (98.675%)\n",
      "Epoch: [97][300/391]\tTime 0.023 (0.024)\tData 0.001 (0.002)\tLoss 0.0238 (0.0377)\tPrec 99.219% (98.679%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.121 (0.121)\tLoss 0.2701 (0.2701)\tPrec 92.969% (92.969%)\n",
      " * Prec 90.990% \n",
      "best acc: 91.370000\n",
      "Epoch: [98][0/391]\tTime 0.222 (0.222)\tData 0.196 (0.196)\tLoss 0.0487 (0.0487)\tPrec 97.656% (97.656%)\n",
      "Epoch: [98][100/391]\tTime 0.023 (0.026)\tData 0.001 (0.003)\tLoss 0.0687 (0.0382)\tPrec 97.656% (98.778%)\n",
      "Epoch: [98][200/391]\tTime 0.022 (0.024)\tData 0.001 (0.002)\tLoss 0.0505 (0.0365)\tPrec 98.438% (98.846%)\n",
      "Epoch: [98][300/391]\tTime 0.021 (0.023)\tData 0.001 (0.002)\tLoss 0.0452 (0.0361)\tPrec 97.656% (98.848%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.112 (0.112)\tLoss 0.2612 (0.2612)\tPrec 90.625% (90.625%)\n",
      " * Prec 90.840% \n",
      "best acc: 91.370000\n",
      "Epoch: [99][0/391]\tTime 0.198 (0.198)\tData 0.179 (0.179)\tLoss 0.0460 (0.0460)\tPrec 98.438% (98.438%)\n",
      "Epoch: [99][100/391]\tTime 0.021 (0.024)\tData 0.001 (0.003)\tLoss 0.0815 (0.0373)\tPrec 96.875% (98.639%)\n",
      "Epoch: [99][200/391]\tTime 0.022 (0.023)\tData 0.001 (0.002)\tLoss 0.0328 (0.0373)\tPrec 98.438% (98.690%)\n",
      "Epoch: [99][300/391]\tTime 0.021 (0.022)\tData 0.001 (0.002)\tLoss 0.0063 (0.0373)\tPrec 100.000% (98.689%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.116 (0.116)\tLoss 0.2769 (0.2769)\tPrec 92.188% (92.188%)\n",
      " * Prec 91.060% \n",
      "best acc: 91.370000\n"
     ]
    }
   ],
   "source": [
    "# This cell won't be given, but students will complete the training\n",
    "\n",
    "lr = 0.2\n",
    "weight_decay = 1e-4\n",
    "epochs = 100\n",
    "best_prec = 0\n",
    "\n",
    "#model = nn.DataParallel(model).cuda()\n",
    "model.cuda()\n",
    "criterion = nn.CrossEntropyLoss().cuda()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=lr, momentum=0.9, weight_decay=weight_decay)\n",
    "#cudnn.benchmark = True\n",
    "\n",
    "if not os.path.exists('result'):\n",
    "    os.makedirs('result')\n",
    "fdir = 'result/'+str(model_name)\n",
    "if not os.path.exists(fdir):\n",
    "    os.makedirs(fdir)\n",
    "        \n",
    "\n",
    "for epoch in range(0, epochs):\n",
    "    adjust_learning_rate(optimizer, epoch)\n",
    "\n",
    "    train(trainloader, model, criterion, optimizer, epoch)\n",
    "    \n",
    "    # evaluate on test set\n",
    "    print(\"Validation starts\")\n",
    "    prec = validate(testloader, model, criterion)\n",
    "\n",
    "    # remember best precision and save checkpoint\n",
    "    is_best = prec > best_prec\n",
    "    best_prec = max(prec,best_prec)\n",
    "    print('best acc: {:1f}'.format(best_prec))\n",
    "    save_checkpoint({\n",
    "        'epoch': epoch + 1,\n",
    "        'state_dict': model.state_dict(),\n",
    "        'best_prec': best_prec,\n",
    "        'optimizer': optimizer.state_dict(),\n",
    "    }, is_best, fdir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "decreased-harris",
   "metadata": {},
   "outputs": [],
   "source": [
    "# HW\n",
    "\n",
    "#  1. Train with 4 bits for both weight and activation to achieve >90% accuracy\n",
    "#  2. Find x_int and w_int for the 2nd convolution layer\n",
    "#  3. Check the recovered psum has similar value to the un-quantized original psum\n",
    "#     (such as example 1 in W3S2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "entertaining-queensland",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Accuracy: 9137/10000 (91%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "PATH = \"result/VGG16_quantLeaky/model_best.pth.tar\"\n",
    "checkpoint = torch.load(PATH)\n",
    "model.load_state_dict(checkpoint['state_dict'])\n",
    "device = torch.device(\"cuda\") \n",
    "\n",
    "model.cuda()\n",
    "model.eval()\n",
    "\n",
    "test_loss = 0\n",
    "correct = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for data, target in testloader:\n",
    "        data, target = data.to(device), target.to(device) # loading to GPU\n",
    "        output = model(data)\n",
    "        pred = output.argmax(dim=1, keepdim=True)  \n",
    "        correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "test_loss /= len(testloader.dataset)\n",
    "\n",
    "print('\\nTest set: Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "        correct, len(testloader.dataset),\n",
    "        100. * correct / len(testloader.dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ceramic-nigeria",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 -th layer prehooked\n",
      "7 -th layer prehooked\n",
      "12 -th layer prehooked\n",
      "16 -th layer prehooked\n",
      "21 -th layer prehooked\n",
      "25 -th layer prehooked\n",
      "29 -th layer prehooked\n",
      "34 -th layer prehooked\n",
      "38 -th layer prehooked\n",
      "41 -th layer prehooked\n",
      "46 -th layer prehooked\n",
      "50 -th layer prehooked\n",
      "54 -th layer prehooked\n"
     ]
    }
   ],
   "source": [
    "#send an input and grap the value by using prehook like HW3\n",
    "class SaveOutput:\n",
    "    def __init__(self):\n",
    "        self.outputs = []\n",
    "    def __call__(self, module, module_in):\n",
    "        self.outputs.append(module_in)\n",
    "    def clear(self):\n",
    "        self.outputs = []\n",
    "######### Save inputs from selected layer ##########\n",
    "save_output = SaveOutput()\n",
    "i = 0\n",
    "for layer in model.modules():\n",
    "    i = i+1\n",
    "    if isinstance(layer, QuantConv2d):\n",
    "        print(i,\"-th layer prehooked\")\n",
    "        layer.register_forward_pre_hook(save_output)\n",
    "####################################################\n",
    "dataiter = iter(testloader)\n",
    "images, labels = next(dataiter)\n",
    "images = images.to(device)\n",
    "out = model(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "spoken-worst",
   "metadata": {},
   "outputs": [],
   "source": [
    "weight_q = model.features[27].weight_q\n",
    "w_alpha = model.features[27].weight_quant.wgt_alpha\n",
    "w_bit = 4\n",
    "weight_int = weight_q / (w_alpha / (2**(w_bit-1)-1))\n",
    "# print(weight_int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "interior-oxygen",
   "metadata": {},
   "outputs": [],
   "source": [
    "act = save_output.outputs[8][0]\n",
    "act_alpha = model.features[27].act_alpha\n",
    "act_bit = 4\n",
    "act_quant_fn = act_quantization(act_bit)\n",
    "act_q = act_quant_fn(act, act_alpha)\n",
    "act_int = act_q / (act_alpha / (2**act_bit-1))\n",
    "# print(act_int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ranging-porter",
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_int = torch.nn.Conv2d(in_channels = 8, out_channels=8, kernel_size = 3, padding=1)\n",
    "conv_int.weight = torch.nn.parameter.Parameter(weight_int)\n",
    "conv_int.bias = model.features[27].bias\n",
    "output_int = conv_int(act_int)\n",
    "m = nn.LeakyReLU(negative_slope=0.015625)\n",
    "output_recovered = output_int * (act_alpha / (2**act_bit-1)) * (w_alpha /(2**(w_bit-1)-1))\n",
    "output_recovered = m(output_recovered)\n",
    "# print(output_recovered)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "designed-auction",
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_ref = torch.nn.Conv2d(in_channels = 8, out_channels=8, kernel_size = 3, padding=1)\n",
    "conv_ref.weight = model.features[27].weight_q\n",
    "conv_ref.bias = model.features[27].bias\n",
    "output_ref = conv_ref(act)\n",
    "# print(output_ref)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1faa8e73-f27d-4d94-9707-2af2c74a300e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This time, compute your \"psum_recovered\" such as HW5 including ReLU and\n",
    "# compare with your prehooked input for the next layer (instead of your computed\n",
    "# psum_ref).\n",
    "psum_ref = save_output.outputs[9][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "157dffd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(8.9096e-07, device='cuda:0', grad_fn=<MeanBackward0>)\n"
     ]
    }
   ],
   "source": [
    "difference = abs( psum_ref - output_recovered )\n",
    "print(difference.mean())  ## It should be small, e.g.,2.3 in my trainned model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "corresponding-significance",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "exposed-witch",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "entitled-barbados",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "minimal-serbia",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
